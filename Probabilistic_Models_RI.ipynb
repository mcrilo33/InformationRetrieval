{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from IndexerCACM import *\n",
    "from IndexerQuery import *\n",
    "from RelevantParser import *\n",
    "from Query import *\n",
    "from IRmodel import *\n",
    "from Vector import *\n",
    "from IRList import *\n",
    "from EvalMeasure import *\n",
    "from EvalIRModel import *\n",
    "from copy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processed collections \n",
    "collectionPath = 'data/cacm/cacm.txt'\n",
    "collectionPath2 = 'data/cisi/cisi.txt'\n",
    "queriesPath = 'data/cacm/cacm.qry'\n",
    "relevantPath = 'data/cacm/cacm.rel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = IndexerCACM(collectionPath, ParserCACM())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#indexer.createRepIndex()\n",
    "#indexer.createRepInvIndex()\n",
    "#indexer.createRepInvFromAll()\n",
    "\n",
    "queriesIndexer = IndexerQuery(queriesPath, ParserCACM())\n",
    "\n",
    "# If Index isn't already builded\n",
    "#queriesIndexer.createRepIndex()\n",
    "\n",
    "relevantIndexer = Indexer(relevantPath, RelevantParser())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#relevantIndexer.createIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' \\n  \\n   1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)    \\n  \\n   What articles exist which deal with TSS (Time Sharing System), an operating system for IBM computers?', {'comput': 1.0, 'ibm': 1.0, 'deal': 1.0, 'share': 1.0, 'system': 2.0, 'articl': 1.0, 'exist': 1.0, 'operat': 1.0, 'time': 1.0, 'tss': 1.0, -1: 11.0})\n"
     ]
    }
   ],
   "source": [
    "q = query(1, queriesIndexer, relevantIndexer)\n",
    "q2 = query(10, queriesIndexer, relevantIndexer)\n",
    "print(q.text, q.el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P_M(s) = \\prod_{i=1}^n p_M(s_i)$\n",
    "\n",
    "where $P_M(s)$ probability to observe sequence of words $s$ with language model $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use this measure to compare documents with a query so we can be satisfied with something proportional to this (so we can use $\\log$).\n",
    "\n",
    "It leads to this measure :\n",
    "\n",
    "$f(q,d) = \\log P_{M_d}(q) = \\sum_{t\\in q} tf(t,q)\\log p_{M_d}(t)$\n",
    "\n",
    "where $q$ is a query, $d$ a document, $t$ a term.\n",
    "\n",
    "And we have $p_{M_d}(t)$ equal to $\\frac{tf(t,d)}{L(d)}$\n",
    "\n",
    "** Sometimes t from q isn't in d ** it leads to,\n",
    "\n",
    "$\\log p_M(t) = -\\infty $ cad $\\log P_{M_d}(q) = -\\infty$ even if other terms from q give a good similarity with $M_d$.\n",
    "\n",
    "Good method to avoid that is a smoothed prob :\n",
    "\n",
    "$\\log p_M(t) = \\log(\\lambda p_{M_d}(t)+(1-\\lambda)p_{M_c}(t)))$\n",
    "\n",
    "where $M_C$ is the model language on the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LanguageModel(IRmodel):\n",
    "    \n",
    "    def __init__(self, indexer, lbd=0.5):\n",
    "\n",
    "        IRmodel.__init__(self, indexer)\n",
    "        self.lbd = lbd\n",
    "    \n",
    "    def probModelDoc(self, id, element):\n",
    "        \n",
    "        freq = indexer.getEfFromDoc(id)\n",
    "        if element in freq:\n",
    "            return freq[element]/float(freq[-1])\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def probModelAll(self, element):\n",
    "        \n",
    "        if element in indexer.repInvFromAll:\n",
    "            return indexer.repInvFromAll[element] \\\n",
    "                /float(indexer.repInvFromAll[-1])\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    def getScores(self, query):\n",
    "        \n",
    "        query = copy(query)\n",
    "        query.pop(-1)\n",
    "        scores = np.zeros(self.nDoc, [('id', 'a25'), ('score', 'float64')])\n",
    "        \n",
    "        for element in query:\n",
    "            i = 0\n",
    "            if element in self.indexer.invIndex:\n",
    "                docFromElement = self.indexer.getDfFromEl(element)\n",
    "                for id in self.indexer.index:\n",
    "                    scores[i]['id'] = id\n",
    "                    if id in docFromElement:\n",
    "                        scores[i]['score'] += np.log(self.lbd*self.probModelDoc(id, element) \\\n",
    "                        + (1 - self.lbd)*self.probModelAll(element))\n",
    "                    else:\n",
    "                        scores[i]['score'] += np.log((1 - self.lbd)*self.probModelAll(element))\n",
    "                    i += 1\n",
    "                \n",
    "        return np.array(scores)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.92251515388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('2319', -67.93184600084517), ('2621', -68.2297030905898),\n",
       "       ('3025', -69.48244739727727), ('322', -69.71678322154878),\n",
       "       ('1506', -70.26094887662569), ('2625', -70.54158428890301),\n",
       "       ('1544', -70.66576729306766), ('2371', -70.77094753757163),\n",
       "       ('1605', -71.20517610214819), ('2632', -71.4525942458842)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lm = LanguageModel(indexer)\n",
    "scores =  Lm.getRanking(q.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Okapi BM25 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$f(d,q) = \\sum_{t\\in q}idf'(t)\\frac{(k_1+1)tf(t,d)}{k_1((1-b)+bL(d)/L_{mean}+tf(t,d))}$ where,\n",
    "\n",
    "probabilistic $idf'(t) = max(0, \\log\\frac{N-df(t)+0.5}{df(t)+0.5})$.\n",
    "\n",
    "$L_{mean}$ is the mean size of documents.\n",
    "\n",
    "$k_1 \\in [1.2, 2.0]$ and $b = 0.75$ are free parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Okapi(IRmodel):\n",
    "    \n",
    "    def __init__(self, indexer, k=1.5, b=0.75):\n",
    "        \n",
    "        IRmodel.__init__(self, indexer)\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "        \n",
    "        self.nDoc = len(indexer.indexFromCol)\n",
    "        \n",
    "        lMean = 0\n",
    "        for id in indexer.index:\n",
    "            lMean += indexer.index[id][-1]\n",
    "        self.lMean = lMean/len(indexer.index)\n",
    "    \n",
    "    def idf(self, elements):\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for element in elements:\n",
    "            if element in indexer.invIndex:\n",
    "                df = len(indexer.getDfFromEl(element))\n",
    "                result[element] = \\\n",
    "                max(0, np.log((self.nDoc-df+0.5) / (df+0.5)))\n",
    "            else:\n",
    "                result[element] = 0\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def getScores(self, query):\n",
    "        \n",
    "        query = copy(query)\n",
    "        query.pop(-1)\n",
    "        scores = np.zeros(self.nDoc, [('id', 'a25'), ('score', 'float64')])\n",
    "        \n",
    "        idf = self.idf(query)\n",
    "        \n",
    "        for element in query:\n",
    "            i = 0\n",
    "            if element in self.indexer.invIndex:\n",
    "                for id in self.indexer.index:\n",
    "                    tf = self.indexer.getEfFromDoc(id)\n",
    "                    docFromElement = self.indexer.getDfFromEl(element)\n",
    "                    scores[i]['id'] = id\n",
    "                    if id in docFromElement:\n",
    "                        scores[i]['score'] \\\n",
    "                        += idf[element] \\\n",
    "                        * ((self.k + 1) * tf[element]) \\\n",
    "                        / (self.k * ((1 - self.b) + self.b * tf[-1] \\\n",
    "                        / self.lMean) + tf[element])\n",
    "                    i += 1\n",
    "                \n",
    "        return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.2990880013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('4010', 22.76645960714305), ('2319', 21.018766465556922),\n",
       "       ('3546', 20.688723765450447), ('2625', 19.951332108288458),\n",
       "       ('4048', 19.79217919159696), ('3644', 19.528324547205344),\n",
       "       ('2632', 19.309167312890654), ('3442', 19.126193736402666),\n",
       "       ('2950', 18.282477629556013), ('4109', 18.222217182478776)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lm = Okapi(indexer)\n",
    "scores =  Lm.getRanking(q.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EvalMeasure.py:19: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  np.in1d(self.irlist.scores[:i]['id'], self.irlist.query.relevants).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "khachian not in language!\n",
      "im not in language!\n",
      "rap not in language!\n",
      "adaba not in language!\n",
      "co-cit not in language!\n",
      "pram not in language!\n",
      "ecl not in language!\n",
      "class-complet not in language!\n",
      "topographi not in language!\n",
      "tcoll not in language!\n",
      "multi-target not in language!\n",
      "udo not in language!\n",
      "window-manag not in language!\n",
      "fault-toler not in language!\n"
     ]
    }
   ],
   "source": [
    "models = [LanguageModel(indexer, lbd=i) for i in np.linspace(0,1,20)]\n",
    "queries = [query(i, queriesIndexer, relevantIndexer) for i in queriesIndexer.index if i in relevantIndexer.indexFromCol]\n",
    "measures = [EvalPrecisionAverage, EvalPrecisionRecall] \n",
    "\n",
    "EM = EvalIRModel(models, queries, measures)\n",
    "results = EM.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  5.22672494e-04   1.19966509e-03   8.61168794e-04   1.14579745e-07]\n",
      "  [  9.32051766e-04   1.74332957e-03   1.33769067e-03   1.64542918e-07]\n",
      "  [  2.37414816e-03   3.19871118e-03   2.78642967e-03   1.69976044e-07]\n",
      "  ..., \n",
      "  [  0.00000000e+00   5.42005420e-04   2.71002710e-04   7.34424688e-08]\n",
      "  [  2.15081639e-03   3.78861887e-03   2.96971763e-03   6.70599237e-07]\n",
      "  [  0.00000000e+00   1.36239782e-03   6.81198910e-04   4.64031955e-07]]\n",
      "\n",
      " [[  5.22672494e-04   1.19966509e-03   8.61168794e-04   1.14579745e-07]\n",
      "  [  9.32051766e-04   1.74332957e-03   1.33769067e-03   1.64542918e-07]\n",
      "  [  2.37414816e-03   3.19871118e-03   2.78642967e-03   1.69976044e-07]\n",
      "  ..., \n",
      "  [  0.00000000e+00   5.42005420e-04   2.71002710e-04   7.34424688e-08]\n",
      "  [  2.15081639e-03   3.78861887e-03   2.96971763e-03   6.70599237e-07]\n",
      "  [  0.00000000e+00   1.36239782e-03   6.81198910e-04   4.64031955e-07]]\n",
      "\n",
      " [[  5.22672494e-04   1.19966509e-03   8.61168794e-04   1.14579745e-07]\n",
      "  [  9.32051766e-04   1.74332957e-03   1.33769067e-03   1.64542918e-07]\n",
      "  [  2.37414816e-03   3.19871118e-03   2.78642967e-03   1.69976044e-07]\n",
      "  ..., \n",
      "  [  0.00000000e+00   5.42005420e-04   2.71002710e-04   7.34424688e-08]\n",
      "  [  2.15081639e-03   3.78861887e-03   2.96971763e-03   6.70599237e-07]\n",
      "  [  0.00000000e+00   1.36239782e-03   6.81198910e-04   4.64031955e-07]]\n",
      "\n",
      " ..., \n",
      " [[  5.22672494e-04   1.19966509e-03   8.61168794e-04   1.14579745e-07]\n",
      "  [  9.32051766e-04   1.74332957e-03   1.33769067e-03   1.64542918e-07]\n",
      "  [  2.37414816e-03   3.19871118e-03   2.78642967e-03   1.69976044e-07]\n",
      "  ..., \n",
      "  [  0.00000000e+00   5.42005420e-04   2.71002710e-04   7.34424688e-08]\n",
      "  [  2.15081639e-03   3.78861887e-03   2.96971763e-03   6.70599237e-07]\n",
      "  [  0.00000000e+00   1.36239782e-03   6.81198910e-04   4.64031955e-07]]\n",
      "\n",
      " [[  5.22672494e-04   1.19966509e-03   8.61168794e-04   1.14579745e-07]\n",
      "  [  9.32051766e-04   1.74332957e-03   1.33769067e-03   1.64542918e-07]\n",
      "  [  2.37414816e-03   3.19871118e-03   2.78642967e-03   1.69976044e-07]\n",
      "  ..., \n",
      "  [  0.00000000e+00   5.42005420e-04   2.71002710e-04   7.34424688e-08]\n",
      "  [  2.15081639e-03   3.78861887e-03   2.96971763e-03   6.70599237e-07]\n",
      "  [  0.00000000e+00   1.36239782e-03   6.81198910e-04   4.64031955e-07]]\n",
      "\n",
      " [[  5.22672494e-04   1.19966509e-03   8.61168794e-04   1.14579745e-07]\n",
      "  [  9.32051766e-04   1.74332957e-03   1.33769067e-03   1.64542918e-07]\n",
      "  [  2.37414816e-03   3.19871118e-03   2.78642967e-03   1.69976044e-07]\n",
      "  ..., \n",
      "  [  0.00000000e+00   5.42005420e-04   2.71002710e-04   7.34424688e-08]\n",
      "  [  2.15081639e-03   3.78861887e-03   2.96971763e-03   6.70599237e-07]\n",
      "  [  0.00000000e+00   1.36239782e-03   6.81198910e-04   4.64031955e-07]]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Query.Query object at 0x7f32240d1510>, <Query.Query object at 0x7f32240d1410>, <Query.Query object at 0x7f32240d1110>, <Query.Query object at 0x7f32241ed850>, <Query.Query object at 0x7f32241ed8d0>, <Query.Query object at 0x7f32241ed910>, <Query.Query object at 0x7f32241ed990>, <Query.Query object at 0x7f32241ed950>, <Query.Query object at 0x7f32241ed9d0>, <Query.Query object at 0x7f32241eda10>, <Query.Query object at 0x7f32241eda50>, <Query.Query object at 0x7f32241eda90>, <Query.Query object at 0x7f32241edad0>, <Query.Query object at 0x7f32241edb50>, <Query.Query object at 0x7f32241edb10>, <Query.Query object at 0x7f32241edc10>, <Query.Query object at 0x7f32241edc50>, <Query.Query object at 0x7f32241edbd0>, <Query.Query object at 0x7f32241edc90>, <Query.Query object at 0x7f32241edb90>, <Query.Query object at 0x7f32241edd10>, <Query.Query object at 0x7f32241edd50>, <Query.Query object at 0x7f32241edcd0>, <Query.Query object at 0x7f32241edd90>, <Query.Query object at 0x7f32241eddd0>, <Query.Query object at 0x7f32241ede10>, <Query.Query object at 0x7f32241ede50>, <Query.Query object at 0x7f32241ede90>, <Query.Query object at 0x7f32241edf10>, <Query.Query object at 0x7f32241edf50>, <Query.Query object at 0x7f32241edf90>, <Query.Query object at 0x7f32241eded0>, <Query.Query object at 0x7f32241edfd0>, <Query.Query object at 0x7f3223d99090>, <Query.Query object at 0x7f3223d99050>, <Query.Query object at 0x7f3223d990d0>, <Query.Query object at 0x7f3223d99110>, <Query.Query object at 0x7f3223d99150>, <Query.Query object at 0x7f3223d99190>, <Query.Query object at 0x7f3223d991d0>, <Query.Query object at 0x7f3223d99210>, <Query.Query object at 0x7f3223d99250>, <Query.Query object at 0x7f3223d992d0>, <Query.Query object at 0x7f3223d99310>, <Query.Query object at 0x7f3223d99290>, <Query.Query object at 0x7f3223d99350>, <Query.Query object at 0x7f3223d993d0>, <Query.Query object at 0x7f3223d99390>, <Query.Query object at 0x7f3223d99410>, <Query.Query object at 0x7f3223d99490>, <Query.Query object at 0x7f3223d99450>, <Query.Query object at 0x7f3223d99550>]\n"
     ]
    }
   ],
   "source": [
    "len(queriesIndexer.index)\n",
    "queries = [query(i, queriesIndexer, relevantIndexer) for i in queriesIndexer.index if i in relevantIndexer.indexFromCol]\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bad Identifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5674268367c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueriesIndexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevantIndexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mcrilo33/Master/Master2/RI/TP1/Query.pyc\u001b[0m in \u001b[0;36mquery\u001b[0;34m(id, queriesIndexer, relevantIndexer)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueriesIndexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetObjFromDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueriesIndexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEfFromDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrelevants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelevantIndexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetObjFromDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mcrilo33/Master/Master2/RI/TP1/Indexer.pyc\u001b[0m in \u001b[0;36mgetObjFromDoc\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;34m'''Return the object of a doc with identifier==id in Col'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetStrFromDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreateIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mcrilo33/Master/Master2/RI/TP1/Indexer.pyc\u001b[0m in \u001b[0;36mgetStrFromDoc\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;34m'''Return the string of a doc with identifier==id in Col'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectionPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexFromCol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetObjFromDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mcrilo33/Master/Master2/RI/TP1/Indexer.pyc\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(self, rep, index, id)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Rep file does no exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bad Identifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Bad Identifier"
     ]
    }
   ],
   "source": [
    "print(query(35, queriesIndexer, relevantIndexer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
