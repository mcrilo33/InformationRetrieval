{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from IndexerCACM import *\n",
    "from RelevantParser import *\n",
    "from Query import *\n",
    "from copy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processed collections \n",
    "collectionPath = 'data/cacm/cacm.txt'\n",
    "collectionPath2 = 'data/cisi/cisi.txt'\n",
    "queriesPath = 'data/cacm/cacm.qry'\n",
    "relevantPath = 'data/cacm/cacm.rel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = IndexerCACM(collectionPath, ParserCACM())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#indexer.createRepIndex()\n",
    "#indexer.createRepInvIndex()\n",
    "indexer.createRepInvFromAll()\n",
    "\n",
    "queriesIndexer = IndexerCACM(queriesPath, ParserCACM())\n",
    "\n",
    "# If Index isn't already builded\n",
    "#queriesIndexer.createRepIndex()\n",
    "\n",
    "relevantIndexer = Indexer(relevantPath, RelevantParser())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#relevantIndexer.createIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Query.Query object at 0x7fd0880a3690>, <Query.Query object at 0x7fd05c811850>)\n"
     ]
    }
   ],
   "source": [
    "q = query(1, queriesIndexer, relevantIndexer)\n",
    "q2 = query(10, queriesIndexer, relevantIndexer)\n",
    "print(q, q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Weighter(object):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        # Indexer is an Indexer object\n",
    "        self.indexer = indexer\n",
    "        \n",
    "        self.nDoc = len(indexer.indexFromCol)\n",
    "        self.loadIndex = {}\n",
    "        \n",
    "        \n",
    "    def idf(self, elements):\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for element in elements:\n",
    "            if element in indexer.invIndex:\n",
    "                result[element] = \\\n",
    "                np.log(self.nDoc / float(len(indexer.getDfFromEl(element))-1))\n",
    "            else:\n",
    "                result[element] = 0\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def loadWeightsFromDoc(self, name):\n",
    "        \n",
    "        end = re.search(r'\\..*?$', collectionPath).group(0)\n",
    "        self.path = re.sub(r'\\..*?$', name, indexer.collectionPath)+end\n",
    "        self.indexPath = re.sub(r'\\..*?$', 'Index', self.path)+end\n",
    "        \n",
    "        if os.path.isfile(self.indexPath):\n",
    "            indexFile = open(self.indexPath)\n",
    "            self.loadIndex = pickle.load(indexFile)\n",
    "            indexFile.close()\n",
    "        else:\n",
    "            weightsFile = open(self.path, \"w\")\n",
    "            pos = 0\n",
    "            for id in self.indexer.index:\n",
    "                toWrite = ''\n",
    "                elements = self.computeWeightsFromDoc(id)\n",
    "                elements.pop(-1)\n",
    "                for element in elements:\n",
    "                    toWrite += ':'+element+':'+str(elements[element])\n",
    "                toWrite = toWrite[1:]\n",
    "                # Get pos in index and size of current rep\n",
    "                self.loadIndex[id] = [pos, len(toWrite)]\n",
    "                \n",
    "                weightsFile.write(toWrite)\n",
    "                pos += len(toWrite)\n",
    "\n",
    "            weightsFile.close()\n",
    "            \n",
    "            # Indexes'hashtable of doc in col\n",
    "            indexFile = open(self.indexPath, \"w\")\n",
    "            pickle.dump(self.loadIndex, indexFile)\n",
    "        \n",
    "            indexFile.close()\n",
    "            \n",
    "    def getWeightsFromDoc(self, id):\n",
    "        \n",
    "        data = self.indexer.getData(self.path, self.loadIndex, id)\n",
    "        return self.indexer.freqFromData(data)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "        \n",
    "            \n",
    "class Weighter1(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter1'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        return indexer.getEfFromDoc(id)\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        weights = copy(query)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = 1\n",
    "        \n",
    "        return weights\n",
    "        \n",
    "class Weighter2(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter2'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        return indexer.getEfFromDoc(id)\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        weights = copy(query)\n",
    "        \n",
    "        return weights\n",
    "        \n",
    "class Weighter3(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter3'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        return indexer.getEfFromDoc(id)\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        return self.idf(query)\n",
    "\n",
    "class Weighter4(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter4'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        weights = indexer.getEfFromDoc(id)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = 1 + np.log(weights[element])\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        return self.idf(query)\n",
    "                       \n",
    "class Weighter5(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter5'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        weights = indexer.getEfFromDoc(id)\n",
    "        \n",
    "        idf = self.idf(weights)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = \\\n",
    "            (1 + np.log(weights[element])) * idf[element]\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        weights = copy(query)\n",
    "        \n",
    "        idf = self.idf(weights)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = \\\n",
    "            (1 + np.log(weights[element])) * idf[element]\n",
    "            \n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1.0, 'acceler': 1.0, 'process': 1.0, 'solut': 1.0, 'ca': 1.0, 'procedur': 1.0, 'an': 3.0, 'rate': 1.0, 'if': 2.0, 'wegstein': 1.0, 'techniqu': 1.0, 'for': 1.0, 'diverg': 1.0, 'when': 1.0, 'to': 1.0, 'which': 1.0, 'appli': 1.0, 'is': 2.0, 'pm': 1.0, 'march': 1.0, 'induc': 1.0, 'given': 1.0, 'discuss': 1.0, 'jb': 1.0, 'of': 3.0, 'iter': 4.0, 'converg': 4.0, 'exampl': 1.0, 'equat': 1.0, 'illustr': 1.0, 'accelerat': 1.0, 'the': 4.0, -1: 47.0}\n",
      "\n",
      "\n",
      "{'comput': 1, 'deal': 1, 'comp': 1, 'share': 1, 'for': 1, 'lab': 1, 'an': 1, 'exist': 1, 'langmuir': 1, 'with': 1, 'serv': 1, 'what': 1, 'alexand': 1, 'ibm': 1, 'richard': 1, 'system': 1, 'articl': 1, 'operat': 1, 'which': 1, 'time': 1, 'tss': 1, -1: 1}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter1(indexer)\n",
    "print(w.getWeightsFromDoc(20))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1.0, 'acceler': 1.0, 'process': 1.0, 'solut': 1.0, 'ca': 1.0, 'procedur': 1.0, 'an': 3.0, 'rate': 1.0, 'if': 2.0, 'wegstein': 1.0, 'techniqu': 1.0, 'for': 1.0, 'diverg': 1.0, 'when': 1.0, 'to': 1.0, 'which': 1.0, 'appli': 1.0, 'is': 2.0, 'pm': 1.0, 'march': 1.0, 'induc': 1.0, 'given': 1.0, 'discuss': 1.0, 'jb': 1.0, 'of': 3.0, 'iter': 4.0, 'converg': 4.0, 'exampl': 1.0, 'equat': 1.0, 'illustr': 1.0, 'accelerat': 1.0, 'the': 4.0, -1: 47.0}\n",
      "\n",
      "\n",
      "{'comput': 1.0, 'deal': 1.0, 'comp': 1.0, 'share': 1.0, 'for': 1.0, 'lab': 1.0, 'an': 1.0, 'exist': 1.0, 'langmuir': 1.0, 'with': 1.0, 'serv': 1.0, 'what': 1.0, 'alexand': 1.0, 'ibm': 1.0, 'richard': 1.0, 'system': 2.0, 'articl': 1.0, 'operat': 1.0, 'which': 1.0, 'time': 1.0, 'tss': 2.0, -1: 23.0}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter2(indexer)\n",
    "print(w.getWeightsFromDoc(20))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1.0, 'acceler': 1.0, 'process': 1.0, 'solut': 1.0, 'ca': 1.0, 'procedur': 1.0, 'an': 3.0, 'rate': 1.0, 'if': 2.0, 'wegstein': 1.0, 'techniqu': 1.0, 'for': 1.0, 'diverg': 1.0, 'when': 1.0, 'to': 1.0, 'which': 1.0, 'appli': 1.0, 'is': 2.0, 'pm': 1.0, 'march': 1.0, 'induc': 1.0, 'given': 1.0, 'discuss': 1.0, 'jb': 1.0, 'of': 3.0, 'iter': 4.0, 'converg': 4.0, 'exampl': 1.0, 'equat': 1.0, 'illustr': 1.0, 'accelerat': 1.0, 'the': 4.0, -1: 47.0}\n",
      "\n",
      "\n",
      "{'comput': 1.054181210545674, 'deal': 2.6877999211769894, 'share': 2.4973529569391175, 'an': 1.2807435686086692, 'exist': 2.4329950879563147, 'langmuir': 0, 'what': 4.7062055722704557, 'richard': 2.771637699819077, 'system': 1.4300543813371573, 'articl': 2.7792713246741485, 'which': 1.6832165821571556, 'tss': 2.8715210583253672, 'comp': 0, 'lab': 0, 'with': 1.6832165821571556, 'ibm': 2.5177916246163914, 'serv': 2.6704684648253494, 'alexand': 2.8025281868384155, 'for': 1.0239268021878718, 'operat': 3.5075098250453638, 'time': 1.6541924628178752, -1: 0}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter3(indexer)\n",
    "print(w.getWeightsFromDoc(20))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1.0, 'acceler': 1.0, 'process': 1.0, 'solut': 1.0, 'ca': 1.0, 'procedur': 1.0, 'an': 2.09861228867, 'rate': 1.0, 'if': 1.69314718056, 'wegstein': 1.0, 'techniqu': 1.0, 'for': 1.0, 'diverg': 1.0, 'when': 1.0, 'to': 1.0, 'which': 1.0, 'appli': 1.0, 'is': 1.69314718056, 'pm': 1.0, 'march': 1.0, 'induc': 1.0, 'given': 1.0, 'discuss': 1.0, 'jb': 1.0, 'of': 2.09861228867, 'iter': 2.38629436112, 'converg': 2.38629436112, 'exampl': 1.0, 'equat': 1.0, 'illustr': 1.0, 'accelerat': 1.0, 'the': 2.38629436112, -1: 39.742402021820006}\n",
      "\n",
      "\n",
      "{'comput': 1.054181210545674, 'deal': 2.6877999211769894, 'share': 2.4973529569391175, 'an': 1.2807435686086692, 'exist': 2.4329950879563147, 'langmuir': 0, 'what': 4.7062055722704557, 'richard': 2.771637699819077, 'system': 1.4300543813371573, 'articl': 2.7792713246741485, 'which': 1.6832165821571556, 'tss': 2.8715210583253672, 'comp': 0, 'lab': 0, 'with': 1.6832165821571556, 'ibm': 2.5177916246163914, 'serv': 2.6704684648253494, 'alexand': 2.8025281868384155, 'for': 1.0239268021878718, 'operat': 3.5075098250453638, 'time': 1.6541924628178752, -1: 0}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter4(indexer)\n",
    "print(w.getWeightsFromDoc(20))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 0.986873489641, 'acceler': 7.24517944333, 'process': 1.78701337584, 'solut': 2.20390717977, 'ca': 0.224393142385, 'procedur': 2.07469544829, 'an': 2.68778419171, 'rate': 2.65343227767, 'if': 6.31318915518, 'wegstein': 2.69481749384, 'techniqu': 1.9518746186, 'for': 1.02392680219, 'diverg': 2.80252818684, 'when': 3.32651189518, 'to': 1.1052948911, 'which': 1.68321658216, 'appli': 2.3674408227, 'is': 1.5825089658, 'pm': 0.521347002508, 'march': 0.823557175522, 'induc': 2.68779992118, 'given': 1.8745414152, 'discuss': 1.88388727762, 'jb': 0.337090886556, 'of': 1.47773667653, 'iter': 6.07240105947, 'converg': 6.53364930007, 'exampl': 2.23232439249, 'equat': 2.29641955295, 'illustr': 2.57860062921, 'accelerat': 6.55203226277, 'the': 2.02549977368, -1: 82.61147528798199}\n",
      "\n",
      "\n",
      "{'comput': 1.054181210545674, 'deal': 2.6877999211769894, 'comp': 0.0, 'share': 2.4973529569391175, 'for': 1.0239268021878718, 'lab': 0.0, 'an': 1.2807435686086692, 'exist': 2.4329950879563147, 'langmuir': 0.0, 'with': 1.6832165821571556, 'serv': 2.6704684648253494, 'what': 4.7062055722704557, 'alexand': 2.8025281868384155, 'ibm': 2.5177916246163914, 'richard': 2.771637699819077, 'system': 2.4212925438084048, 'articl': 2.7792713246741485, 'operat': 3.5075098250453638, 'which': 1.6832165821571556, 'time': 1.6541924628178752, 'tss': 4.8619077838221063, -1: 0.0}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter5(indexer)\n",
    "print(w.getWeightsFromDoc(20))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q.el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IRmodel(object):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        # indexer is an indexer object\n",
    "        self.indexer = indexer\n",
    "        self.nDoc = len(indexer.indexFromCol)\n",
    "        \n",
    "    def getScores(self, query):\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "    \n",
    "    def getRanking(self, query):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        scores = self.getScores(query)\n",
    "        sorted_scores = (np.sort(scores, order='score'))[::-1]\n",
    "        \n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        \n",
    "        return sorted_scores\n",
    "\n",
    "class Vector(IRmodel):\n",
    "    \n",
    "    def __init__(self, indexer, weighter=Weighter1, normalized=False):\n",
    "    \n",
    "        IRmodel.__init__(self, indexer)\n",
    "        \n",
    "        # weighter is a Weighter object\n",
    "        self.weighter = weighter(indexer)\n",
    "        \n",
    "        # normalized is a boolean\n",
    "        self.normalized = normalized\n",
    "    \n",
    "    def dotProduct(self, vector1, vector2):\n",
    "        \n",
    "        result = 0\n",
    "        \n",
    "        if len(vector1)>len(vector2):\n",
    "            tmp = vector1\n",
    "            vector1 = vector2\n",
    "            vector2 = tmp\n",
    "        \n",
    "        for element in vector1:\n",
    "            if element in vector2:\n",
    "                result += vector1[element]*vector2[element]\n",
    "        \n",
    "        return result\n",
    "                \n",
    "    def norm1(self, vector):\n",
    "        \n",
    "        result = 0\n",
    "        \n",
    "        for element in vector:\n",
    "            result += abs(vector[element])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def getScores(self, query):\n",
    "        \n",
    "        vecQuery = self.weighter.getWeightsFromQuery(query)\n",
    "        norm1VecQuery = self.norm1(vecQuery)\n",
    "        \n",
    "        doc = {}\n",
    "        \n",
    "        for id in query:\n",
    "            \n",
    "            if id in self.indexer.invIndex:\n",
    "                for element in self.indexer.getDfFromEl(id):\n",
    "                    doc[element] = 1\n",
    "        doc.pop(-1)\n",
    "        \n",
    "        scores = np.zeros(len(doc), [('id', 'a25'), ('score', 'float64')])\n",
    "        \n",
    "        i = 0\n",
    "        for id in doc:\n",
    "            \n",
    "            scores[i]['id'] = str(id)\n",
    "            vecDoc = self.weighter.getWeightsFromDoc(id)\n",
    "            dotProduct = self.dotProduct(vecDoc, vecQuery)\n",
    "            \n",
    "            if self.normalized: \n",
    "                scores[i]['score'] = dotProduct/float(self.norm1(vecDoc)*norm1VecQuery)\n",
    "            else:\n",
    "                scores[i]['score'] = dotProduct\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return np.array(scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07602405548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('3742', 4547.0), ('3444', 4545.0), ('3512', 4526.0),\n",
       "       ('3480', 4526.0), ('3215', 4526.0), ('3415', 4521.0),\n",
       "       ('3843', 4520.0), ('3619', 4520.0), ('4141', 4515.0),\n",
       "       ('3634', 4515.0)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = Vector(indexer, Weighter1)\n",
    "scores = vector1.getRanking(q.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34476089478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('594', 0.028409090909090908), ('2796', 0.028409090909090908),\n",
       "       ('2917', 0.02807486631016043), ('2329', 0.02807486631016043),\n",
       "       ('143', 0.02807486631016043), ('275', 0.027972027972027972),\n",
       "       ('9', 0.027777777777777776), ('80', 0.027777777777777776),\n",
       "       ('557', 0.027777777777777776), ('34', 0.027777777777777776)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm1 = Vector(indexer, Weighter1, normalized=True)\n",
    "scores = vectorNorm1.getRanking(q.el)[:10]\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27697682381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('594', 0.2536231884057971), ('294', 0.2536231884057971),\n",
       "       ('2796', 0.2536231884057971), ('2690', 0.2536231884057971),\n",
       "       ('2311', 0.2536231884057971), ('197', 0.2536231884057971),\n",
       "       ('1461', 0.2536231884057971), ('2853', 0.25339673913043476),\n",
       "       ('1304', 0.25337331334332835), ('275', 0.25334448160535117)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm2 = Vector(indexer, Weighter2, normalized=True)\n",
    "scores = vectorNorm2.getRanking(q.el)[:10]\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.37277293205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('195', 0.006994187441045503), ('1461', 0.006522688023303906),\n",
       "       ('2796', 0.006160944944785141), ('3068', 0.0046455647822142955),\n",
       "       ('1069', 0.004427273171593947), ('31', 0.004276397872586725),\n",
       "       ('143', 0.0042143757311462506), ('234', 0.004210856012993603),\n",
       "       ('1247', 0.003934211393161682), ('2371', 0.003906939044365772)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm3 = Vector(indexer, Weighter3, normalized=True)\n",
    "scores = vectorNorm3.getRanking(q.el)[:10]\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53560519218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('195', 0.006994187441045503), ('1461', 0.006522688023303906),\n",
       "       ('2796', 0.006160944944785141), ('1069', 0.004427273171593947),\n",
       "       ('31', 0.004276397872586725), ('143', 0.0042143757311462506),\n",
       "       ('234', 0.004210856012993603), ('61', 0.003741848138513384),\n",
       "       ('289', 0.0037022337888048037), ('594', 0.0037002725523431726)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm4 = Vector(indexer, Weighter4, normalized=True)\n",
    "scores = vectorNorm4.getRanking(q.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6320130825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('195', 0.01962876435762631), ('1461', 0.01362311543995687),\n",
       "       ('2796', 0.008666266953654524), ('1069', 0.006805058212962663),\n",
       "       ('289', 0.006468487030047001), ('163', 0.005396430103933236),\n",
       "       ('718', 0.005059766743091413), ('325', 0.004963377368845642),\n",
       "       ('339', 0.0048272901333964394), ('2312', 0.004703600168072482)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm5 = Vector(indexer, Weighter5, normalized=True)\n",
    "scores = vectorNorm5.getRanking(q.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IRList(object):\n",
    "    \n",
    "    def __init__(self, query, scores):\n",
    "        \n",
    "        self.query = query\n",
    "        self.scores = scores\n",
    "\n",
    "irlist = IRList(q, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EvalMeasure():\n",
    "    \n",
    "    def __init__(self, irlist):\n",
    "        \n",
    "        self.irlist = irlist\n",
    "        \n",
    "    def recall(self, i):\n",
    "        \n",
    "        recall = \\\n",
    "        np.in1d(irlist.scores[:i]['id'], irlist.query.relevants).sum()\n",
    "        \n",
    "        return recall/float(len(irlist.query.relevants))\n",
    "    \n",
    "    def precision(self, i):\n",
    "        \n",
    "        precision = \\\n",
    "        np.in1d(irlist.scores[:i]['id'], irlist.query.relevants).sum()\n",
    "    \n",
    "        return precision/float(i)\n",
    "    \n",
    "    def eval(self, k):\n",
    "    \n",
    "        raise ValueError('Abstract method')\n",
    "        \n",
    "class EvalPrecisionRecall(EvalMeasure):\n",
    "    \n",
    "    def __init__(self, irlist):\n",
    "        \n",
    "        EvalMeasure.__init__(self, irlist)\n",
    "        \n",
    "        size = len(self.irlist.scores)\n",
    "        self.recalls = np.zeros(size)\n",
    "        self.precisions = np.zeros(size)\n",
    "        for i in range(1, size):\n",
    "            self.recalls[i] = self.recall(i)\n",
    "            self.precisions[i] = self.precision(i)\n",
    "        self.recalls = np.array(self.recalls)\n",
    "        self.precisions = np.array(self.precisions)\n",
    "        \n",
    "    def eval(self, k=1):\n",
    "        \n",
    "        measures = []\n",
    "        \n",
    "        # gives good levels between 0 and 1\n",
    "        levels = [(1/float(k+1))*l for l in range(1, k+1)]\n",
    "        \n",
    "        i = 0\n",
    "        for level in levels:\n",
    "            measures.append((level, np.max(self.precisions[np.where(self.recalls >= level)])))\n",
    "            i += 1\n",
    "            \n",
    "        if k==1:\n",
    "            return measures[0][1]\n",
    "        \n",
    "        return measures\n",
    "\n",
    "class EvalPrecisionAverage(EvalMeasure):\n",
    "    \n",
    "    def __init__(self, irlist):\n",
    "        \n",
    "        EvalMeasure.__init__(self, irlist)\n",
    "        \n",
    "    def eval(self):\n",
    "        \n",
    "        self.irlist.query.relevants = np.array(self.irlist.query.relevants)\n",
    "        return np.mean([self.precision(i) for i in np.argwhere(np.in1d(self.irlist.scores['id'], self.irlist.query.relevants[:,0]))])\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.16666666666666666, 0.012605042016806723), (0.3333333333333333, 0.012605042016806723), (0.5, 0.012605042016806723), (0.6666666666666666, 0.0106951871657754), (0.8333333333333333, 0.0072992700729927005)]\n"
     ]
    }
   ],
   "source": [
    "EM = EvalPrecisionRecall(irlist)\n",
    "print(EM.eval(k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00509925501757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcrilo33/.anaconda3/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:15: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "EM = EvalPrecisionAverage(irlist)\n",
    "print(EM.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvalIRModel(object):\n",
    "    \n",
    "    def __init__(self, models, queries, measures):\n",
    "        \n",
    "        self.models = models\n",
    "        self.queries = queries\n",
    "        self.measures = measures\n",
    "        self.results()\n",
    "        \n",
    "    def results(self):\n",
    "        \n",
    "        results = np.zeros((len(self.models), len(self.queries), len(self.measures)+2))\n",
    "        \n",
    "        i = 0\n",
    "        for model in self.models:\n",
    "            j = 0\n",
    "            for query in self.queries:\n",
    "                k = 0\n",
    "                scores = model.getScores(query.el)\n",
    "                irlist = IRList(query, scores)\n",
    "                for measure in self.measures:\n",
    "                    measure = measure(irlist)\n",
    "                    results[i,j,k] = measure.eval()\n",
    "                    k += 1\n",
    "                results[i,j,-2] = np.mean(results[i,j,:-2])\n",
    "                results[i,j,-1] = np.var(results[i,j,:-2])\n",
    "                j += 1\n",
    "            i += 1\n",
    "        \n",
    "        self.outcome = results\n",
    "    \n",
    "    def getResults(self):\n",
    "        \n",
    "        return self.outcome\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcrilo33/.anaconda3/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:15: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  4.83268942e-03,   1.26050420e-02,   8.71886572e-03,\n",
       "           1.51023662e-05],\n",
       "        [  4.86343544e-03,   1.26050420e-02,   8.73423873e-03,\n",
       "           1.49831181e-05]],\n",
       "\n",
       "       [[  4.83268942e-03,   1.26050420e-02,   8.71886572e-03,\n",
       "           1.51023662e-05],\n",
       "        [  4.86343544e-03,   1.26050420e-02,   8.73423873e-03,\n",
       "           1.49831181e-05]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EM = EvalIRModel([vectorNorm1, vectorNorm2], [q, q2], [EvalPrecisionAverage, EvalPrecisionRecall])\n",
    "EM.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
