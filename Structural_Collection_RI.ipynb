{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from IndexerCACM import *\n",
    "from RelevantParser import *\n",
    "from Query import *\n",
    "from IRmodel import *\n",
    "from Vector import *\n",
    "from IRList import *\n",
    "from EvalMeasure import *\n",
    "from EvalIRModel import *\n",
    "from copy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processed collections \n",
    "collectionPath = 'data/cacm/cacm.txt'\n",
    "collectionPath2 = 'data/cisi/cisi.txt'\n",
    "queriesPath = 'data/cacm/cacm.qry'\n",
    "relevantPath = 'data/cacm/cacm.rel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer = IndexerCACM(collectionPath, ParserCACM())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#indexer.createRepIndex()\n",
    "#indexer.createRepInvIndex()\n",
    "#indexer.createRepInvFromAll()\n",
    "indexer.createLinkIndex()\n",
    "\n",
    "queriesIndexer = IndexerCACM(queriesPath, ParserCACM())\n",
    "\n",
    "# If Index isn't already builded\n",
    "#queriesIndexer.createRepIndex()\n",
    "\n",
    "relevantIndexer = Indexer(relevantPath, RelevantParser())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#relevantIndexer.createIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1213' '1437' '1562' '1661' '171' '2143' '2336' '2509' '2518' '2983' '532'\n",
      " '65' '997']\n"
     ]
    }
   ],
   "source": [
    "print(indexer.getLinkFromDoc(4026))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Query.Query object at 0x7f26683e9bd0>, <Query.Query object at 0x7f263a517050>, <Query.Query object at 0x7f2647848cd0>, <Query.Query object at 0x7f263a573090>)\n"
     ]
    }
   ],
   "source": [
    "q = query(1, queriesIndexer, relevantIndexer)\n",
    "q2 = query(2, queriesIndexer, relevantIndexer)\n",
    "q3 = query(3, queriesIndexer, relevantIndexer)\n",
    "q4 = query(4, queriesIndexer, relevantIndexer)\n",
    "print(q, q2, q3, q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnhancedIRmodel(IRmodel):\n",
    "    \n",
    "    def __init__(self, indexer, seedModel, n=10, k=1):\n",
    "        \n",
    "        IRmodel.__init__(self, indexer)\n",
    "        \n",
    "        self.seedModel = seedModel\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        \n",
    "    def enlarge(self, graph):\n",
    "\n",
    "        self.graph = copy(graph)\n",
    "        goTo = {}\n",
    "\n",
    "        for node in self.indexer.index:\n",
    "            links = self.indexer.getLinkFromDoc(node)\n",
    "            if links[0] != '':\n",
    "                for id in links:\n",
    "                    if node in graph:\n",
    "                        self.graph[id] = 1\n",
    "                    if id not in goTo:\n",
    "                        goTo[id] = [node]\n",
    "                    else:\n",
    "                        goTo[id].append(node)\n",
    "\n",
    "        for node in graph:\n",
    "            if node in goTo:\n",
    "                for id in np.random.permutation(goTo[node])[:self.k]:\n",
    "                    self.graph[id] = 1\n",
    "\n",
    "        i = 0\n",
    "        self.idToInt = {}\n",
    "        self.intToId = {}\n",
    "        for id in self.graph:\n",
    "            self.idToInt[id] = i\n",
    "            self.intToId[i] = id\n",
    "            i += 1\n",
    "\n",
    "        graphSize = len(self.graph)\n",
    "        self.links = np.zeros((graphSize, graphSize))\n",
    "\n",
    "        for id2 in range(graphSize):\n",
    "            links = self.indexer.getLinkFromDoc(self.intToId[id2])\n",
    "            if links[0] != '':\n",
    "                for link in links:\n",
    "                    if link in self.idToInt:\n",
    "                        id1 = self.idToInt[link]\n",
    "                        self.links[id1,id2] = 1\n",
    "                        \n",
    "    def getSeeds(self, query):\n",
    "        \n",
    "        seeds = {}\n",
    "        \n",
    "        idSeeds = self.seedModel.getRanking(query)[:self.n]['id']\n",
    "        for id in idSeeds:\n",
    "            seeds[id] = 1\n",
    "        \n",
    "        self.enlarge(seeds)\n",
    "                \n",
    "    def randomWalk(self):\n",
    "                \n",
    "        raise ValueError('Abstract method')\n",
    "        \n",
    "    def getScores(self, query):\n",
    "        \n",
    "        self.getSeeds(query)\n",
    "        \n",
    "        return self.randomWalk()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random walk :\n",
    "Pages and Links represented by a graph $G = (V,E)$\n",
    "1. Let $p_t$ the current page at time $t$.\n",
    "\n",
    "2. $\\begin{cases} \\text{With prob }d\\text{ we click on a link of }p_t \\text{ or we go randomly if there is no link} \\\\\n",
    "\\text{With prob }1-d\\text{ we go randomly on another webpage}\\end{cases}$\n",
    "\n",
    "We have :\n",
    "\n",
    "$\\mu^{t+1} = \\frac{1-d}{N}+dA\\mu^{t} \\text{ with } A_{i,j} = \n",
    "\\begin{cases} \\frac{1}{N} \\text{ if } l_j = 0 \\\\\n",
    "\\frac{1}{l_j} \\text{ if } j\\in P_i\\\\\n",
    "0 \\text{ otherwise}\n",
    "\\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PageRank(EnhancedIRmodel):\n",
    "    \n",
    "    def __init__(self, indexer, seedModel, n=3000, k=500, d=0.5, cvg=10e-20):\n",
    "        \n",
    "        EnhancedIRmodel.__init__(self, indexer, seedModel=seedModel, n=n, k=k)\n",
    "        self.d = d\n",
    "        self.cvg = cvg\n",
    "        \n",
    "    def randomWalk(self):\n",
    "        \n",
    "        mu = []\n",
    "        graphSize = len(self.graph)\n",
    "            \n",
    "        mu.append(np.zeros(graphSize) + (1-self.d)/graphSize)\n",
    "        A = np.zeros((graphSize, graphSize))\n",
    "        \n",
    "        for id2 in range(graphSize):\n",
    "            nLink = self.links[:,id2].sum()\n",
    "            if nLink==0:\n",
    "                A[:,id2] = 1/float(graphSize)\n",
    "            else:\n",
    "                for id1 in range(graphSize):\n",
    "                    if self.links[id1, id2]==1:\n",
    "                        A[id1, id2] = 1/nLink\n",
    "        \n",
    "        while(True):\n",
    "            mu.append((1-self.d)/float(graphSize) + self.d*np.dot(A, mu[-1]))\n",
    "            if np.linalg.norm(mu[-2]-mu[-1])<self.cvg: break\n",
    "        \n",
    "        scores = np.zeros(self.nDoc, [('id', 'a25'), ('score', 'float64')])\n",
    "        i = 0\n",
    "        for id in self.indexer.index:\n",
    "            scores[i]['id'] = id\n",
    "            if id in self.idToInt:\n",
    "                scores[i]['score'] = mu[-1][self.idToInt[id]]\n",
    "            else:\n",
    "                scores[i]['score'] = 0\n",
    "            i += 1\n",
    "            \n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.6417448521\n",
      "[('1781', 0.0016822435371162308) ('1491', 0.0010995973044106281)\n",
      " ('1945', 0.0010370644180610576) ('196', 0.0010346694474851021)\n",
      " ('3184', 0.0010306799658475908) ('1265', 0.0008862635588820515)\n",
      " ('1787', 0.0008639875004658949) ('1860', 0.0008548099934897967)\n",
      " ('1751', 0.0008370815198640582) ('2017', 0.0008111151236692741)]\n"
     ]
    }
   ],
   "source": [
    "vector = Vector(indexer)\n",
    "em = PageRank(indexer, vector)\n",
    "scores = em.getRanking(q2.el)\n",
    "print(scores[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hits Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pages and Links represented by a graph $G = (V,E)$, at step $t$ :\n",
    "\n",
    "**autority nodes : ** $a^{t}_{i} = \\sum_{j,i\\rightarrow j\\in E}a_{j}^{t-1} / ||a^{t-1}||_2$\n",
    "\n",
    "**hub nodes : ** $h^{t}_{i} = \\sum_{j,j\\rightarrow i\\in E}h_{j}^{t-1} / ||h^{t-1}||_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Hits(EnhancedIRmodel):\n",
    "    \n",
    "    def __init__(self, indexer, seedModel, n=5, k=5, cvg=10e-6):\n",
    "        \n",
    "        EnhancedIRmodel.__init__(self, indexer, seedModel=seedModel, n=n, k=k)\n",
    "        self.cvg = cvg\n",
    "        \n",
    "    def randomWalk(self):\n",
    "        \n",
    "        autority = []\n",
    "        hub = []\n",
    "        graphSize = len(self.graph)\n",
    "        autority.append(np.zeros(graphSize) + 1)\n",
    "        hub.append(np.zeros(graphSize) + 1)\n",
    "        A = self.links \n",
    "        B = np.transpose(A)\n",
    "        \n",
    "        while(True):\n",
    "            autority.append(np.dot(A, hub[-1]))\n",
    "            autority[-1] = autority[-1]/float(np.linalg.norm(autority[-1]))\n",
    "            hub.append(np.dot(B, autority[-1]))\n",
    "            hub[-1] = hub[-1]/float(np.linalg.norm(hub[-1]))\n",
    "            if np.linalg.norm(autority[-2]-autority[-1])<self.cvg \\\n",
    "                and np.linalg.norm(hub[-2]-hub[-1])<self.cvg: break\n",
    "        \n",
    "        scores = np.zeros(self.nDoc, [('id', 'a25'), ('score', 'float64')])\n",
    "        i = 0\n",
    "        for id in self.indexer.index:\n",
    "            scores[i]['id'] = id\n",
    "            if id in self.idToInt:\n",
    "                scores[i]['score'] = autority[-1][self.idToInt[id]]\n",
    "            else:\n",
    "                scores[i]['score'] = 0\n",
    "            i += 1\n",
    "            \n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2714', 0.49806072643596444) ('3075', 0.43357107626700286)\n",
      " ('2664', 0.43357107626700286) ('2557', 0.43357107626700286)\n",
      " ('2289', 0.43357107626700286) ('1974', 5.4022579149911475e-06)\n",
      " ('2971', 4.1467293051285935e-06) ('2534', 4.1467293051285935e-06)\n",
      " ('1835', 4.1467293051285935e-06) ('335', 6.969450230556098e-12)]\n"
     ]
    }
   ],
   "source": [
    "vector = Vector(indexer)\n",
    "em = Hits(indexer, vector)\n",
    "scores = em.getRanking(q2.el)\n",
    "print(scores[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
