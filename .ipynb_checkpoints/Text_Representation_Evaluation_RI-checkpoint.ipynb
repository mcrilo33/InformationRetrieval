{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IndexerCACM import *\n",
    "from IndexerQuery import *\n",
    "from RelevantParser import *\n",
    "from Query import *\n",
    "from copy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processed collections \n",
    "collectionPath = 'data/cacm/cacm.txt'\n",
    "collectionPath2 = 'data/cisi/cisi.txt'\n",
    "queriesPath = 'data/cacm/cacm.qry'\n",
    "relevantPath = 'data/cacm/cacm.rel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = IndexerCACM(collectionPath, ParserCACM())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#indexer.createRepIndex()\n",
    "#indexer.createRepInvIndex()\n",
    "#indexer.createRepInvFromAll()\n",
    "\n",
    "queriesIndexer = IndexerCACM(queriesPath, ParserCACM())\n",
    "\n",
    "# If Index isn't already builded\n",
    "#queriesIndexer.createRepIndex()\n",
    "\n",
    "relevantIndexer = Indexer(relevantPath, RelevantParser())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#relevantIndexer.createIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Query.Query object at 0x7f478b2df310>, <Query.Query object at 0x7f4769648210>, <Query.Query object at 0x7f4769648250>, <Query.Query object at 0x7f4769648290>)\n"
     ]
    }
   ],
   "source": [
    "q = query(1, queriesIndexer, relevantIndexer)\n",
    "q2 = query(2, queriesIndexer, relevantIndexer)\n",
    "q3 = query(3, queriesIndexer, relevantIndexer)\n",
    "q4 = query(4, queriesIndexer, relevantIndexer)\n",
    "print(q, q2, q3, q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Weighter(object):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        # Indexer is an Indexer object\n",
    "        self.indexer = indexer\n",
    "        \n",
    "        self.nDoc = len(indexer.indexFromCol)\n",
    "        self.loadIndex = {}\n",
    "        \n",
    "        \n",
    "    def idf(self, elements):\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for element in elements:\n",
    "            if element in indexer.invIndex:\n",
    "                result[element] = \\\n",
    "                self.nDoc / float(len(indexer.getDfFromEl(element))-1)\n",
    "            else:\n",
    "                result[element] = 0\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def loadWeightsFromDoc(self, name):\n",
    "        \n",
    "        end = re.search(r'\\..*?$', collectionPath).group(0)\n",
    "        self.path = re.sub(r'\\..*?$', name, indexer.collectionPath)+end\n",
    "        self.indexPath = re.sub(r'\\..*?$', 'Index', self.path)+end\n",
    "        \n",
    "        if os.path.isfile(self.indexPath):\n",
    "            indexFile = open(self.indexPath)\n",
    "            self.loadIndex = pickle.load(indexFile)\n",
    "            indexFile.close()\n",
    "        else:\n",
    "            weightsFile = open(self.path, \"w\")\n",
    "            pos = 0\n",
    "            for id in self.indexer.index:\n",
    "                toWrite = ''\n",
    "                elements = self.computeWeightsFromDoc(id)\n",
    "                elements.pop(-1)\n",
    "                for element in elements:\n",
    "                    toWrite += ':'+element+':'+str(elements[element])\n",
    "                toWrite = toWrite[1:]\n",
    "                # Get pos in index and size of current rep\n",
    "                self.loadIndex[id] = [pos, len(toWrite)]\n",
    "                \n",
    "                weightsFile.write(toWrite)\n",
    "                pos += len(toWrite)\n",
    "\n",
    "            weightsFile.close()\n",
    "            \n",
    "            # Indexes'hashtable of doc in col\n",
    "            indexFile = open(self.indexPath, \"w\")\n",
    "            pickle.dump(self.loadIndex, indexFile)\n",
    "        \n",
    "            indexFile.close()\n",
    "            \n",
    "    def getWeightsFromDoc(self, id):\n",
    "        \n",
    "        data = self.indexer.getData(self.path, self.loadIndex, id)\n",
    "        return self.indexer.freqFromData(data)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "        \n",
    "            \n",
    "class Weighter1(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter1'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        return indexer.getEfFromDoc(id)\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        weights = copy(query)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = 1\n",
    "        \n",
    "        return weights\n",
    "        \n",
    "class Weighter2(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter2'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        return indexer.getEfFromDoc(id)\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        weights = copy(query)\n",
    "        \n",
    "        return weights\n",
    "        \n",
    "class Weighter3(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter3'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        return indexer.getEfFromDoc(id)\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        return self.idf(query)\n",
    "\n",
    "class Weighter4(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter4'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        weights = indexer.getEfFromDoc(id)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = 1 + np.log(weights[element])\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        return self.idf(query)\n",
    "                       \n",
    "class Weighter5(Weighter):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        Weighter.__init__(self, indexer)\n",
    "        name = 'Weighter5'\n",
    "        self.loadWeightsFromDoc(name)\n",
    "        \n",
    "    def computeWeightsFromDoc(self, id):\n",
    "        \n",
    "        weights = indexer.getEfFromDoc(id)\n",
    "        \n",
    "        idf = self.idf(weights)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = \\\n",
    "            (1 + np.log(weights[element])) * idf[element]\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def getWeightsFromQuery(self, query):\n",
    "        \n",
    "        weights = copy(query)\n",
    "        \n",
    "        idf = self.idf(weights)\n",
    "        \n",
    "        for element in weights:\n",
    "            weights[element] = \\\n",
    "            (1 + np.log(weights[element])) * idf[element]\n",
    "            \n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wegstein': 1.0, 'illustr': 1.0, 'appli': 1.0, 'acceler': 1.0, 'procedur': 1.0, 'rate': 1.0, 'techniqu': 1.0, 'diverg': 1.0, 'solut': 1.0, 'A': 1.0, 'H': 1.0, 'induc': 1.0, 'J': 1.0, 'Iter': 1.0, 'Converg': 1.0, 'Accelerat': 1.0, 'discuss': 1.0, 'Process': 1.0, 'iter': 2.0, 'An': 1.0, 'converg': 2.0, 'exampl': 1.0, 'equat': 1.0, -1: 25.0}\n",
      "\n",
      "\n",
      "{'What': 1, 'comput': 1, 'IBM': 1, 'deal': 1, 'Share': 1, 'System': 1, 'articl': 1, 'exist': 1, 'operat': 1, 'Time': 1, 'TSS': 1, -1: 1}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter1(indexer)\n",
    "print(w.getWeightsFromDoc(20))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comput': 1.0, 'On': 1.0, 'illustr': 1.0, 'appli': 1.0, 'Solut': 1.0, 'procedur': 1.0, 'Ellenberg': 1.0, 'high': 1.0, 'rule': 1.0, 'polynomial': 1.0, 'pitfal': 1.0, 'Bairstow': 1.0, 'shown': 1.0, 'rapid': 1.0, 'techniqu': 2.0, 'Numer': 3.0, 'invers': 1.0, 'accuraci': 1.0, 'circumv': 1.0, 'iter': 1.0, 'basic': 1.0, 'K': 1.0, 'By': 1.0, 'applic': 1.0, 'Equation': 1.0, 'recommend': 2.0, 'realiz': 1.0, 'scale': 1.0, 'W': 1.0, 'Programm': 1.0, 'present': 1.0, 'great': 1.0, 'reliabl': 1.0, 'Newton': 1.0, 'Raphson': 1.0, 'converg': 1.0, 'degre': 1.0, 'exampl': 1.0, 'Both': 1.0, 'equat': 1.0, 'Polynomial': 1.0, 'root': 1.0, -1: 46.0}\n",
      "\n",
      "\n",
      "{'B': 1.0, 'I': 1.0, 'Priev': 2.0, 'written': 1.0, 'articl': 1.0, 'Pooch': 2.0, 'U': 1.0, 'interest': 1.0, 'Udo': 1.0, -1: 11.0}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter2(indexer)\n",
    "print(w.getWeightsFromDoc(111))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q2.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Comment': 1.0, 'Feurzeig': 1.0, 'E': 1.0, 'W': 1.0, -1: 12.0, 'Procedur': 1.0, '60': 1.0, 'T': 1.0, 'Iron': 1.0, 'Implement': 1.0, 'Recurs': 1.0, 'ALGOL': 1.0, 'Block': 1.0}\n",
      "\n",
      "\n",
      "{'compil': 10.057416267942584, 'multi': 14.250847457627119, 'target': 15.343065693430656, 'TCOLL': 0, 'Intermedi': 4204.0, 'construct': 10.457711442786069, 'languag': 6.780645161290322, -1: 0}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter3(indexer)\n",
    "print(w.getWeightsFromDoc(400))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q3.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Comment': 1.0, 'Feurzeig': 1.0, 'E': 1.0, 'W': 1.0, -1: 12.0, 'Procedur': 1.0, '60': 1.0, 'T': 1.0, 'Iron': 1.0, 'Implement': 1.0, 'Recurs': 1.0, 'ALGOL': 1.0, 'Block': 1.0}\n",
      "\n",
      "\n",
      "{'process': 6.2373887240356085, 'abstract': 13.261829652996845, 'procedur': 8.544715447154472, 'oppos': 1051.0, 'theoret': 12.73939393939394, 'pass': 13.605177993527509, 'disjoint': 15.231884057971014, 'messag': 13.828947368421053, 'Remot': 1051.0, 'call': 11.180851063829786, 'interest': 168.16, 'communicat': 420.4, 'complet': 12.437869822485206, 'distribut': 11.84225352112676, 'I': 25.17365269461078, 'mechan': 12.817073170731707, 'problem': 5.997146932952925, 'possibl': 14.013333333333334, 'work': 11.486338797814208, 'descript': 11.677777777777777, 'exampl': 9.93853427895981, 'environ': 8.275590551181102, 'exclus': 233.55555555555554, 'implement': 8.74012474012474, -1: 0}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter4(indexer)\n",
    "print(w.getWeightsFromDoc(400))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q4.el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comput': 3.24884080371, 'On': 32.5891472868, 'illustr': 13.3885350318, 'appli': 10.8911917098, 'Solut': 50.6506024096, 'procedur': 8.54471544715, 'Ellenberg': 2102.0, 'high': 13.346031746, 'rule': 11.5178082192, 'polynomial': 52.55, 'pitfal': 16.2945736434, 'Bairstow': 600.571428571, 'shown': 8.74012474012, 'rapid': 14.8028169014, 'techniqu': 12.9183135156, 'Numer': 180.052368603, 'invers': 105.1, 'accuraci': 15.3430656934, 'circumv': 16.421875, 'iter': 13.1375, 'basic': 11.8757062147, 'K': 22.9726775956, 'By': 93.4222222222, 'applic': 8.2431372549, 'Equation': 51.9012345679, 'recommend': 26.0732261798, 'realiz': 14.1073825503, 'scale': 14.1548821549, 'W': 9.64220183486, 'Programm': 22.847826087, 'present': 5.50261780105, 'great': 14.8551236749, 'reliabl': 13.6493506494, 'Newton': 135.612903226, 'Raphson': 600.571428571, 'converg': 15.6865671642, 'degre': 89.4468085106, 'exampl': 9.93853427896, 'Both': 127.393939394, 'equat': 10.6972010178, 'Polynomial': 56.0533333333, 'root': 13.0965732087, -1: 4649.8538168140485}\n",
      "\n",
      "\n",
      "{'distribut': 11.842253521126761, 'process': 6.2373887240356085, 'abstract': 13.261829652996845, 'procedur': 8.5447154471544717, 'disjoint': 15.231884057971014, 'mechan': 21.701191302054909, 'messag': 13.828947368421053, 'pass': 13.605177993527509, 'oppos': 1051.0, 'problem': 5.9971469329529246, 'I': 42.622699084275517, 'possibl': 14.013333333333334, 'work': 11.486338797814208, 'descript': 11.677777777777777, 'theoret': 12.73939393939394, 'Remot': 1051.0, 'exampl': 9.9385342789598106, 'call': 11.180851063829786, 'interest': 168.16, 'exclus': 233.55555555555554, 'environ': 8.2755905511811019, 'implement': 8.7401247401247399, 'communicat': 420.39999999999998, -1: 0.0, 'complet': 12.437869822485206}\n"
     ]
    }
   ],
   "source": [
    "w = Weighter5(indexer)\n",
    "print(w.getWeightsFromDoc(111))\n",
    "print('\\n')\n",
    "print(w.getWeightsFromQuery(q4.el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IRmodel(object):\n",
    "    \n",
    "    def __init__(self, indexer):\n",
    "        \n",
    "        # indexer is an indexer object\n",
    "        self.indexer = indexer\n",
    "        self.nDoc = len(indexer.indexFromCol)\n",
    "        \n",
    "    def getScores(self, query):\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "    \n",
    "    def getRanking(self, query):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        scores = self.getScores(query)\n",
    "        sorted_scores = (np.sort(scores, order='score'))[::-1]\n",
    "        \n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        \n",
    "        return sorted_scores\n",
    "\n",
    "class Vector(IRmodel):\n",
    "    \n",
    "    def __init__(self, indexer, weighter=Weighter1, normalized=False):\n",
    "    \n",
    "        IRmodel.__init__(self, indexer)\n",
    "        \n",
    "        # weighter is a Weighter object\n",
    "        self.weighter = weighter(indexer)\n",
    "        \n",
    "        # normalized is a boolean\n",
    "        self.normalized = normalized\n",
    "    \n",
    "    def dotProduct(self, vector1, vector2):\n",
    "        \n",
    "        result = 0\n",
    "        \n",
    "        if len(vector1)>len(vector2):\n",
    "            tmp = vector1\n",
    "            vector1 = vector2\n",
    "            vector2 = tmp\n",
    "        \n",
    "        for element in vector1:\n",
    "            if element in vector2:\n",
    "                result += vector1[element]*vector2[element]\n",
    "        \n",
    "        return result\n",
    "                \n",
    "    def norm2(self, vector):\n",
    "        \n",
    "        result = 0\n",
    "        \n",
    "        for element in vector:\n",
    "            result += np.power(vector[element], 2)\n",
    "        \n",
    "        return np.sqrt(result)\n",
    "    \n",
    "    def getScores(self, query):\n",
    "        \n",
    "        vecQuery = self.weighter.getWeightsFromQuery(query)\n",
    "        vecQuery.pop(-1)\n",
    "        norm2VecQuery = self.norm2(vecQuery)\n",
    "        \n",
    "        doc = {}\n",
    "        \n",
    "        for id in query:\n",
    "            \n",
    "            if id in self.indexer.invIndex:\n",
    "                for element in self.indexer.getDfFromEl(id):\n",
    "                    doc[element] = id\n",
    "        doc.pop(-1)\n",
    "        \n",
    "        scores = np.zeros(self.nDoc, [('id', 'a25'), ('score', 'float64')])\n",
    "        \n",
    "        i = 0 \n",
    "        for id in self.indexer.index:\n",
    "            \n",
    "            scores[i]['id'] = str(id)\n",
    "            \n",
    "            if id in doc:\n",
    "                vecDoc = self.weighter.getWeightsFromDoc(id)\n",
    "                vecDoc.pop(-1)\n",
    "                dotProduct = self.dotProduct(vecDoc, vecQuery)\n",
    "\n",
    "                if self.normalized: \n",
    "                    scores[i]['score'] = dotProduct/float(self.norm2(vecDoc)*norm2VecQuery)\n",
    "                else:\n",
    "                    scores[i]['score'] = dotProduct\n",
    "\n",
    "            else:\n",
    "                scores[i]['score'] = 0\n",
    "                \n",
    "            i += 1\n",
    "        \n",
    "        return np.array(scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38761115074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('1922', 24.0), ('4084', 19.0), ('4048', 19.0), ('3332', 19.0),\n",
       "       ('4152', 18.0), ('3461', 18.0), ('3911', 17.0), ('3840', 17.0),\n",
       "       ('3637', 17.0), ('3372', 17.0)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = Vector(indexer, Weighter1)\n",
    "scores = vector1.getRanking(q4.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3645188808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('3128', 0.26854307776478736), ('1601', 0.21320071635561047),\n",
       "       ('3043', 0.20272121351984582), ('1588', 0.20257967806063143),\n",
       "       ('3101', 0.199204768222399), ('2376', 0.18609684207969418),\n",
       "       ('1530', 0.17201561551404668), ('2377', 0.1689343445998715),\n",
       "       ('2152', 0.16835875742536846), ('824', 0.16666666666666669)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm1 = Vector(indexer, Weighter1, normalized=True)\n",
    "scores = vectorNorm1.getRanking(q4.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3963270187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('3128', 0.2882306768491569), ('1588', 0.24590447683052283),\n",
       "       ('1530', 0.2417728402451219), ('3059', 0.23939782946951918),\n",
       "       ('3101', 0.2138089935299395), ('2377', 0.2115392598254248),\n",
       "       ('2376', 0.20806259464411975), ('1601', 0.19069251784911845),\n",
       "       ('2166', 0.18257418583505536), ('3043', 0.18131936556464984)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm2 = Vector(indexer, Weighter2, normalized=True)\n",
    "scores = vectorNorm2.getRanking(q4.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.4996881485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('1325', 0.0699317984268452), ('1550', 0.06714205438480218),\n",
       "       ('1135', 0.06209709842107191), ('2519', 0.05817034745389737),\n",
       "       ('2342', 0.05457254331254995), ('2501', 0.0501026359196736),\n",
       "       ('1681', 0.046022018607429126), ('2359', 0.0449677594563381),\n",
       "       ('1829', 0.04263605771675477), ('3041', 0.040472625634702934)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm3 = Vector(indexer, Weighter3, normalized=True)\n",
    "scores = vectorNorm3.getRanking(q4.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2735040188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('1550', 0.07918145694508417), ('1325', 0.07449260761367496),\n",
       "       ('1135', 0.06919815193666695), ('2501', 0.0650217011690884),\n",
       "       ('2359', 0.06082364310271595), ('1829', 0.0607209242961512),\n",
       "       ('1681', 0.05977021287621712), ('3041', 0.05901044457082188),\n",
       "       ('2519', 0.057955028577259676), ('2342', 0.05281884886916953)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm4 = Vector(indexer, Weighter4, normalized=True)\n",
    "scores = vectorNorm4.getRanking(q4.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.9790391922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('1135', 0.14483061709178638), ('1325', 0.10260641141079291),\n",
       "       ('1550', 0.09323034694287828), ('2519', 0.09094601526466026),\n",
       "       ('1829', 0.07427957876369132), ('3073', 0.07257440143648919),\n",
       "       ('2359', 0.06642339610218967), ('1681', 0.06560282928348392),\n",
       "       ('2501', 0.05542593819472901), ('2342', 0.05192728693027786)], \n",
       "      dtype=[('id', 'S25'), ('score', '<f8')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorNorm5 = Vector(indexer, Weighter5, normalized=True)\n",
    "scores = vectorNorm5.getRanking(q4.el)\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IRList(object):\n",
    "    \n",
    "    def __init__(self, query, scores):\n",
    "        \n",
    "        self.query = query\n",
    "        self.scores = scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EvalMeasure():\n",
    "    \n",
    "    def __init__(self, irlist):\n",
    "        \n",
    "        self.irlist = irlist\n",
    "        \n",
    "    def recall(self, i):\n",
    "        \n",
    "        recall = \\\n",
    "        np.in1d(self.irlist.scores[:i]['id'], self.irlist.query.relevants).sum()\n",
    "        \n",
    "        return recall/float(len(self.irlist.query.relevants))\n",
    "    \n",
    "    def precision(self, i):\n",
    "        \n",
    "        precision = \\\n",
    "        np.in1d(self.irlist.scores[:i]['id'], self.irlist.query.relevants).sum()\n",
    "    \n",
    "        return precision/float(i)\n",
    "    \n",
    "    def eval(self, k):\n",
    "    \n",
    "        raise ValueError('Abstract method')\n",
    "        \n",
    "class EvalPrecisionRecall(EvalMeasure):\n",
    "    \n",
    "    def __init__(self, irlist):\n",
    "        \n",
    "        EvalMeasure.__init__(self, irlist)\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        size = len(self.irlist.scores)\n",
    "        self.recalls = np.zeros(size)\n",
    "        self.precisions = np.zeros(size)\n",
    "        for i in range(1, size):\n",
    "            self.recalls[i] = self.recall(i)\n",
    "            self.precisions[i] = self.precision(i)\n",
    "        self.recalls = np.array(self.recalls)\n",
    "        self.precisions = np.array(self.precisions)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        \n",
    "    def eval(self, k=20):\n",
    "        \n",
    "        measures = np.zeros((k, 2))\n",
    "        \n",
    "        # gives good levels between 0 and 1\n",
    "        levels = np.linspace(0, 1, k)\n",
    "        \n",
    "        i = 0\n",
    "        for level in levels:\n",
    "            measures[i,0] = level\n",
    "            wh = self.precisions[np.where(self.recalls >= level)]\n",
    "            if len(wh) > 0:\n",
    "                measures[i,1] = np.max(wh)\n",
    "            else:\n",
    "                measures[i,1] = 0\n",
    "            i += 1\n",
    "            \n",
    "        return measures\n",
    "\n",
    "class EvalPrecisionAverage(EvalMeasure):\n",
    "    \n",
    "    def __init__(self, irlist):\n",
    "        \n",
    "        EvalMeasure.__init__(self, irlist)\n",
    "        \n",
    "    def eval(self):\n",
    "        \n",
    "        self.irlist.query.relevants = np.array(self.irlist.query.relevants)\n",
    "        return np.mean([self.precision(i) for i in np.argwhere(np.in1d(self.irlist.scores['id'], self.irlist.query.relevants[:,0]))])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1550', 0.07918145694508417) ('1325', 0.07449260761367496)\n",
      " ('1135', 0.06919815193666695) ..., ('100', 0.0) ('10', 0.0) ('1', 0.0)]\n",
      "8.45885705948\n",
      "[[ 0.          0.16666667]\n",
      " [ 0.11111111  0.16666667]\n",
      " [ 0.22222222  0.16666667]\n",
      " [ 0.33333333  0.14814815]\n",
      " [ 0.44444444  0.04      ]\n",
      " [ 0.55555556  0.02734375]\n",
      " [ 0.66666667  0.0230179 ]\n",
      " [ 0.77777778  0.01148106]\n",
      " [ 0.88888889  0.00351662]\n",
      " [ 1.          0.00349548]]\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "irlist = IRList(q4, scores)\n",
    "EM = EvalPrecisionRecall(irlist)\n",
    "scores = EM.eval(k=10)\n",
    "print(scores)\n",
    "plt.plot(scores[:,0], scores[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00896619066302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcrilo33/.anaconda3/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:15: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "EM = EvalPrecisionAverage(irlist)\n",
    "print(EM.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvalIRModel(object):\n",
    "    \n",
    "    def __init__(self, models, queries, measures):\n",
    "        \n",
    "        self.models = models\n",
    "        self.queries = queries\n",
    "        self.measures = measures\n",
    "        self.results()\n",
    "        \n",
    "    def results(self):\n",
    "        \n",
    "        results = np.zeros((len(self.models), len(self.queries), len(self.measures)+2))\n",
    "        \n",
    "        i = 0\n",
    "        for model in self.models:\n",
    "            j = 0\n",
    "            for query in self.queries:\n",
    "                k = 0\n",
    "                scores = model.getScores(query.el)\n",
    "                irlist = IRList(query, scores)\n",
    "                for measure in self.measures:\n",
    "                    measure = measure(irlist)\n",
    "                    results[i,j,k] = measure.eval()\n",
    "                    k += 1\n",
    "                results[i,j,-2] = np.mean(results[i,j,:-2])\n",
    "                results[i,j,-1] = np.var(results[i,j,:-2])\n",
    "                j += 1\n",
    "            i += 1\n",
    "        \n",
    "        self.outcome = results\n",
    "    \n",
    "    def getResults(self):\n",
    "        \n",
    "        return self.outcome\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "queries = [query(i, queriesIndexer, relevantIndexer) for i in queriesIndexer.index if i in relevantIndexer.indexFromCol]\n",
    "EM = EvalIRModel([vectorNorm1, vectorNorm2], queries, [EvalPrecisionAverage, EvalPrecisionRecall])\n",
    "results = EM.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
