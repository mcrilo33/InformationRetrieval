{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ParserCACM import *\n",
    "import string\n",
    "import linecache as lin\n",
    "from porter import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Weighter(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.docTotal = 4203\n",
    "        self.fo = open(\"cacm.txt\", \"rw+\")\n",
    "        self.fi = open(\"cacmInv.txt\", \"rw+\")\n",
    "        self.dicStem, self.dicSize = self.parseIndex(\"cacmInvIndex.txt\")\n",
    "        \n",
    "        \n",
    "    def parseIndex(self,f):\n",
    "        fi = open(f,\"r\")\n",
    "        d = {}\n",
    "        e = {}\n",
    "        for i in fi.readlines():\n",
    "            j = i.split(\" \")\n",
    "            d[j[0]] = int(j[1])\n",
    "            e[j[0]] = int(j[2].split('\\n')[0])\n",
    "        fi.close()\n",
    "        return d, e\n",
    "    \n",
    "    def getDocWeightsForDoc(self,idDoc):\n",
    "        print('Undefined...')\n",
    "    \n",
    "    def getDocWeightsForStem(self,stem):\n",
    "        if stem not in self.dicStem:\n",
    "            return 'nope pas dans le dictionnaire'\n",
    "        self.fi.seek(self.dicStem[stem],0)\n",
    "        a = self.fi.read(self.dicSize[stem])\n",
    "        d = {}\n",
    "        for i in a.split(\" \")[2:]:\n",
    "            d[int(i.split(':')[0])]=int(i.split(':')[1])\n",
    "        return d\n",
    " \n",
    "    def getWeightsForQuery(self,query):\n",
    "        print('Undefined...')\n",
    "                \n",
    "            \n",
    "class Weighter1(Weighter):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Weighter.__init__(self)\n",
    "        \n",
    "    def getDocWeightsForDoc(self, idDoc):\n",
    "        n1 = lin.getline(\"cacmIndex.txt\",idDoc)\n",
    "        n2 = lin.getline(\"cacmIndex.txt\",idDoc+1)\n",
    "        total = int(lin.getline(\"cacmTotal.txt\", idDoc))\n",
    "        l  = int(n2) - int(n1)\n",
    "        self.fo.seek(int(n1),0)\n",
    "        a = self.fo.read(l)\n",
    "        t = [x.split() for x in a.split(' : ')[1].split('\\n')[0].split(\";\")]\n",
    "        \n",
    "        dic = {}\n",
    "        for index in range(len(t)-1):\n",
    "            w = t[index]\n",
    "            dic[w[0]]=int(w[1])/float(total)\n",
    "        return dic\n",
    "    \n",
    "    def getWeightsForQuery(self,query):\n",
    "        for stem in query:\n",
    "           query[stem] = 1 \n",
    "        return dic\n",
    "    \n",
    "class Weighter2(Weighter):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Weighter.__init__(self)\n",
    "        \n",
    "    def getDocWeightsForDoc(self, idDoc):\n",
    "        n1 = lin.getline(\"cacmIndex.txt\",idDoc)\n",
    "        n2 = lin.getline(\"cacmIndex.txt\",idDoc+1)\n",
    "        total = int(lin.getline(\"cacmTotal.txt\", idDoc))\n",
    "        l  = int(n2) - int(n1)\n",
    "        self.fo.seek(int(n1),0)\n",
    "        a = self.fo.read(l)\n",
    "        t = [x.split() for x in a.split(' : ')[1].split('\\n')[0].split(\";\")]\n",
    "        \n",
    "        dic = {}\n",
    "        for index in range(len(t)-1):\n",
    "            w = t[index]\n",
    "            dic[w[0]]=int(w[1])/float(total)\n",
    "        return dic\n",
    "    \n",
    "    def getWeightsForQuery(self,query):\n",
    "        return query\n",
    "    \n",
    "class Weighter3(Weighter):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Weighter.__init__(self)\n",
    "        \n",
    "    def getDocWeightsForDoc(self, idDoc):\n",
    "        n1 = lin.getline(\"cacmIndex.txt\",idDoc)\n",
    "        n2 = lin.getline(\"cacmIndex.txt\",idDoc+1)\n",
    "        total = int(lin.getline(\"cacmTotal.txt\", idDoc))\n",
    "        l  = int(n2) - int(n1)\n",
    "        self.fo.seek(int(n1),0)\n",
    "        a = self.fo.read(l)\n",
    "        t = [x.split() for x in a.split(' : ')[1].split('\\n')[0].split(\";\")]\n",
    "        \n",
    "        dic = {}\n",
    "        for index in range(len(t)-1):\n",
    "            w = t[index]\n",
    "            dic[w[0]]=int(w[1])/float(total)\n",
    "        return dic\n",
    "    \n",
    "    def getWeightsForQuery(self,query):\n",
    "        for stem in query:\n",
    "           query[stem] = self.docTotal/len(self.getDocWeightsForStem(stem))\n",
    "        return query\n",
    "    \n",
    "class Weighter4(Weighter):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Weighter.__init__(self)\n",
    "        \n",
    "    def getDocWeightsForDoc(self, idDoc):\n",
    "        n1 = lin.getline(\"cacmIndex.txt\",idDoc)\n",
    "        n2 = lin.getline(\"cacmIndex.txt\",idDoc+1)\n",
    "        total = int(lin.getline(\"cacmTotal.txt\", idDoc))\n",
    "        l  = int(n2) - int(n1)\n",
    "        self.fo.seek(int(n1),0)\n",
    "        a = self.fo.read(l)\n",
    "        t = [x.split() for x in a.split(' : ')[1].split('\\n')[0].split(\";\")]\n",
    "        \n",
    "        dic = {}\n",
    "        for index in range(len(t)-1):\n",
    "            w = t[index]\n",
    "            dic[w[0]]=(1+np.log(int(w[1])/float(total)))\n",
    "        return dic\n",
    "    \n",
    "    def getWeightsForQuery(self,query):\n",
    "        dic = {}\n",
    "        for stem in query:\n",
    "           query[stem] = self.docTotal/len(self.getDocWeightsForStem(stem))\n",
    "        return query\n",
    "    \n",
    "class Weighter5(Weighter):\n",
    "    \n",
    "    def __init__(self):\n",
    "        Weighter.__init__(self)\n",
    "        \n",
    "    def getDocWeightsForDoc(self, idDoc):\n",
    "        n1 = lin.getline(\"cacmIndex.txt\",idDoc)\n",
    "        n2 = lin.getline(\"cacmIndex.txt\",idDoc+1)\n",
    "        total = int(lin.getline(\"cacmTotal.txt\", idDoc))\n",
    "        l  = int(n2) - int(n1)\n",
    "        self.fo.seek(int(n1),0)\n",
    "        a = self.fo.read(l)\n",
    "        t = [x.split() for x in a.split(' : ')[1].split('\\n')[0].split(\";\")]\n",
    "        \n",
    "        dic = {}\n",
    "        for index in range(len(t)-1):\n",
    "            w = t[index]\n",
    "            idf = self.docTotal/len(self.getDocWeightsForStem(w[0]))\n",
    "            dic[w[0]]=(1+np.log(int(w[1])/float(total)))*idf\n",
    "        return dic\n",
    "    \n",
    "    def getWeightsForQuery(self,query):\n",
    "        dic = {}\n",
    "        for stem in query:\n",
    "           idf = self.docTotal/len(self.getDocWeightsForStem(stem))\n",
    "           query[stem] = (1+np.log(query[stem])) * idf\n",
    "        return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{125: 1,\n",
       " 245: 1,\n",
       " 764: 1,\n",
       " 883: 1,\n",
       " 1344: 1,\n",
       " 1422: 1,\n",
       " 1542: 1,\n",
       " 1577: 1,\n",
       " 1597: 1,\n",
       " 1615: 1,\n",
       " 1631: 1,\n",
       " 1639: 1,\n",
       " 1663: 1,\n",
       " 1815: 1,\n",
       " 1875: 1,\n",
       " 2147: 1,\n",
       " 2409: 1,\n",
       " 2778: 1,\n",
       " 3137: 1,\n",
       " 3204: 1,\n",
       " 3209: 1,\n",
       " 3212: 1,\n",
       " 3214: 1,\n",
       " 3220: 1,\n",
       " 3222: 1,\n",
       " 3224: 1,\n",
       " 3229: 2,\n",
       " 3230: 1,\n",
       " 3232: 1,\n",
       " 3234: 1,\n",
       " 3237: 1,\n",
       " 3240: 2,\n",
       " 3243: 2,\n",
       " 3245: 1,\n",
       " 3246: 1,\n",
       " 3249: 1,\n",
       " 3263: 2,\n",
       " 3265: 2,\n",
       " 3267: 1,\n",
       " 3269: 1,\n",
       " 3272: 1,\n",
       " 3276: 2,\n",
       " 3283: 2,\n",
       " 3287: 1,\n",
       " 3289: 1,\n",
       " 3301: 1,\n",
       " 3305: 2,\n",
       " 3315: 1,\n",
       " 3317: 1,\n",
       " 3320: 1,\n",
       " 3323: 1,\n",
       " 3324: 1,\n",
       " 3330: 1,\n",
       " 3350: 1,\n",
       " 3355: 2,\n",
       " 3370: 2,\n",
       " 3374: 1,\n",
       " 3376: 1,\n",
       " 3379: 2,\n",
       " 3381: 1,\n",
       " 3391: 1,\n",
       " 3393: 1,\n",
       " 3397: 1,\n",
       " 3405: 2,\n",
       " 3408: 2,\n",
       " 3424: 1,\n",
       " 3426: 1,\n",
       " 3435: 1,\n",
       " 3448: 2,\n",
       " 3450: 1,\n",
       " 3452: 1,\n",
       " 3459: 1,\n",
       " 3460: 1,\n",
       " 3461: 1,\n",
       " 3468: 3,\n",
       " 3478: 1,\n",
       " 3479: 1,\n",
       " 3482: 1,\n",
       " 3489: 1,\n",
       " 3496: 1,\n",
       " 3498: 1,\n",
       " 3500: 1,\n",
       " 3501: 1,\n",
       " 3508: 1,\n",
       " 3509: 1,\n",
       " 3513: 1,\n",
       " 3514: 1,\n",
       " 3515: 1,\n",
       " 3517: 1,\n",
       " 3520: 1,\n",
       " 3522: 1,\n",
       " 3525: 1,\n",
       " 3528: 2,\n",
       " 3529: 1,\n",
       " 3532: 1,\n",
       " 3538: 1,\n",
       " 3542: 1,\n",
       " 3543: 2,\n",
       " 3554: 1,\n",
       " 3556: 1,\n",
       " 3560: 2,\n",
       " 3564: 1,\n",
       " 3567: 1,\n",
       " 3569: 1,\n",
       " 3571: 1,\n",
       " 3575: 1,\n",
       " 3579: 2,\n",
       " 3581: 1,\n",
       " 3585: 1,\n",
       " 3587: 1,\n",
       " 3590: 1,\n",
       " 3594: 1,\n",
       " 3596: 1,\n",
       " 3597: 1,\n",
       " 3601: 2,\n",
       " 3607: 1,\n",
       " 3609: 1,\n",
       " 3611: 1,\n",
       " 3617: 2,\n",
       " 3620: 1,\n",
       " 3622: 2,\n",
       " 3626: 2,\n",
       " 3630: 2,\n",
       " 3631: 2,\n",
       " 3638: 2,\n",
       " 3645: 1,\n",
       " 3651: 1,\n",
       " 3654: 1,\n",
       " 3655: 1,\n",
       " 3662: 1,\n",
       " 3665: 1,\n",
       " 3666: 1,\n",
       " 3667: 2,\n",
       " 3668: 2,\n",
       " 3671: 3,\n",
       " 3672: 1,\n",
       " 3674: 1,\n",
       " 3678: 1,\n",
       " 3679: 1,\n",
       " 3692: 1,\n",
       " 3693: 1,\n",
       " 3699: 2,\n",
       " 3702: 2,\n",
       " 3713: 2,\n",
       " 3718: 1,\n",
       " 3725: 1,\n",
       " 3729: 1,\n",
       " 3732: 1,\n",
       " 3739: 1,\n",
       " 3740: 1,\n",
       " 3741: 1,\n",
       " 3745: 1,\n",
       " 3748: 2,\n",
       " 3749: 1,\n",
       " 3750: 3,\n",
       " 3751: 1,\n",
       " 3756: 1,\n",
       " 3758: 1,\n",
       " 3766: 1,\n",
       " 3775: 2,\n",
       " 3779: 1,\n",
       " 3780: 1,\n",
       " 3781: 2,\n",
       " 3782: 1,\n",
       " 3788: 1,\n",
       " 3790: 1,\n",
       " 3794: 1,\n",
       " 3796: 1,\n",
       " 3799: 2,\n",
       " 3801: 1,\n",
       " 3802: 1,\n",
       " 3803: 1,\n",
       " 3806: 1,\n",
       " 3815: 1,\n",
       " 3819: 1,\n",
       " 3822: 1,\n",
       " 3824: 1,\n",
       " 3827: 2,\n",
       " 3830: 1,\n",
       " 3836: 1,\n",
       " 3837: 1,\n",
       " 3838: 1,\n",
       " 3841: 1,\n",
       " 3844: 1,\n",
       " 3846: 1,\n",
       " 3848: 1,\n",
       " 3849: 1,\n",
       " 3851: 1,\n",
       " 3861: 2,\n",
       " 3867: 1,\n",
       " 3868: 2,\n",
       " 3869: 1,\n",
       " 3870: 1,\n",
       " 3873: 1,\n",
       " 3882: 2,\n",
       " 3885: 2,\n",
       " 3886: 1,\n",
       " 3889: 1,\n",
       " 3890: 1,\n",
       " 3895: 1,\n",
       " 3896: 1,\n",
       " 3899: 2,\n",
       " 3913: 1,\n",
       " 3915: 1,\n",
       " 3921: 1,\n",
       " 3937: 1,\n",
       " 3954: 2,\n",
       " 3955: 1,\n",
       " 3958: 1,\n",
       " 3961: 1,\n",
       " 3966: 2,\n",
       " 3970: 1,\n",
       " 3972: 1,\n",
       " 3973: 2,\n",
       " 3975: 1,\n",
       " 3976: 1,\n",
       " 3979: 1,\n",
       " 3980: 2,\n",
       " 3983: 1,\n",
       " 3986: 2,\n",
       " 3987: 1,\n",
       " 3993: 1,\n",
       " 3999: 1,\n",
       " 4003: 1,\n",
       " 4009: 2,\n",
       " 4013: 2,\n",
       " 4015: 1,\n",
       " 4016: 1,\n",
       " 4022: 1,\n",
       " 4028: 1,\n",
       " 4029: 1,\n",
       " 4032: 1,\n",
       " 4033: 1,\n",
       " 4037: 1,\n",
       " 4040: 1,\n",
       " 4043: 2,\n",
       " 4050: 1,\n",
       " 4056: 1,\n",
       " 4064: 2,\n",
       " 4065: 2,\n",
       " 4066: 1,\n",
       " 4068: 1,\n",
       " 4072: 1,\n",
       " 4076: 2,\n",
       " 4077: 1,\n",
       " 4078: 1,\n",
       " 4079: 1,\n",
       " 4085: 1,\n",
       " 4087: 1,\n",
       " 4093: 2,\n",
       " 4095: 1,\n",
       " 4102: 1,\n",
       " 4103: 1,\n",
       " 4105: 1,\n",
       " 4111: 1,\n",
       " 4121: 2,\n",
       " 4127: 1,\n",
       " 4128: 1,\n",
       " 4130: 1,\n",
       " 4133: 1,\n",
       " 4136: 2,\n",
       " 4137: 1,\n",
       " 4139: 1,\n",
       " 4140: 1,\n",
       " 4141: 1,\n",
       " 4144: 1,\n",
       " 4145: 1,\n",
       " 4150: 1,\n",
       " 4151: 1,\n",
       " 4152: 1,\n",
       " 4160: 1,\n",
       " 4162: 1,\n",
       " 4164: 1,\n",
       " 4166: 1,\n",
       " 4169: 1,\n",
       " 4180: 1,\n",
       " 4181: 1,\n",
       " 4182: 1,\n",
       " 4184: 1,\n",
       " 4199: 1,\n",
       " 4202: 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('0')\n",
    "w = Weighter1()\n",
    "w.getDocWeightsForStem('orthogon')\n",
    "#print len(w.getDocWeightsForStem(\"bit\"))\n",
    "#print len(w.dicSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "class IRmodel(object):\n",
    "    \n",
    "    def __init__(self, weighter=Weighter1()):\n",
    "        self.docTotal = 4203\n",
    "        self.w = weighter\n",
    "    \n",
    "    def getScores(self,query):\n",
    "        #methode 1 easy one \n",
    "        score = {}\n",
    "        for i in range(1,self.docTotal):\n",
    "            score[i] =  0\n",
    "            query = self.w.getWeightsForQuery(query)\n",
    "            poids_doc = self.w.getDocWeightsForDoc(i)\n",
    "            for w in query :\n",
    "                if w in poids_doc:\n",
    "                    \n",
    "                    score[i] += int(query[w]) * int(poids_doc[w])\n",
    "        return score\n",
    "        \n",
    "    def getRanking(self,query):\n",
    "        \n",
    "        s = self.getScores(query)\n",
    "        sorted_score = sorted(s.items(), key=operator.itemgetter(1))\n",
    "        sorted_score = list(reversed(sorted_score))\n",
    "        return sorted_score\n",
    "    \n",
    "\n",
    "class Vectoriel(IRmodel):\n",
    "    \n",
    "    def __init__(self, weighter=Weighter1(), normalized = True):\n",
    "        IRmodel.__init__(self, weighter=weighter)\n",
    "        self.normalized = normalized\n",
    "        self.normVecDoc = {}\n",
    "        for i in range(1,self.docTotal):\n",
    "            self.normVecDoc[i] = {}\n",
    "            poids_doc = self.w.getDocWeightsForDoc(i)\n",
    "            s = []\n",
    "           \n",
    "            for p in poids_doc:\n",
    "                s.append(poids_doc[p])\n",
    "            s = s/np.linalg.norm(s,2)\n",
    "            for j,p in enumerate(poids_doc):\n",
    "                self.normVecDoc[i][p] = s[j]\n",
    "        \n",
    "            \n",
    "            \n",
    "    def getScores(self,query):\n",
    "        if self.normalized:\n",
    "            \n",
    "            return IRmodel().getScores(query)\n",
    "        \n",
    "        else:\n",
    "            score = {}\n",
    "            s = []\n",
    "            query_norm ={}\n",
    "            for p in query:\n",
    "                s.append(query[p])\n",
    "            s = s/np.linalg.norm(s,2)\n",
    "            for j,p in enumerate(query):\n",
    "                query_norm[p] = s[j]\n",
    "        \n",
    "            for i in range(1,4203):#Ã  corriger\n",
    "                score[i] =  0\n",
    "                poids_doc = self.w.getDocWeightsForDoc(i)\n",
    "                for w in query :\n",
    "                    if w in poids_doc:\n",
    "                        score[i] += query_norm[w] * self.normVecDoc[i][w]\n",
    "            return score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "V = Vectoriel(False)\n",
    "Q = Vectoriel(True)\n",
    "#a = I.getRanking({'improv': 1, 'redund': 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print V.getScores({'improv': 1, 'redund': 1})\n",
    "#print Q.getRanking({'improv': 1, 'redund': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 digit 1\n",
      "1 repeat 1\n",
      "2 comput 1\n",
      "3 extract 1\n",
      "4 root 1\n",
      "5 subtract 1\n"
     ]
    }
   ],
   "source": [
    "p ={'digit': 1, 'repeat': 1, 'comput': 1, 'extract': 1, 'root': 1, 'subtract': 1}\n",
    "\n",
    "for i,j in enumerate(p):\n",
    "\n",
    "    print i,j,p[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ParserCACM import *\n",
    "\n",
    "class QueryParser():\n",
    "    \n",
    "    def __init__(self,doc=\"cacm/cacm.qry\"):\n",
    "        self.par =  ParserCACM()\n",
    "        self.par.initFile(doc)\n",
    "        self.longueur = 0\n",
    "        while self.par.nextDocument():\n",
    "            self.longueur+=1\n",
    "        self.par.initFile(doc)\n",
    "        self.makeRelevant()\n",
    "        \n",
    "    def makeRelevant(self):\n",
    "        fo = open(\"cacm/cacm.rel\", \"r\")\n",
    "        self.rel = [[] for i in range(self.longueur)]\n",
    "        for l in fo.readlines():\n",
    "            l=l.replace(\"  \",\" \")\n",
    "            l=l.replace(\"\\n\",\"\")\n",
    "            ll = l.split(' ')\n",
    "            self.rel[int(ll[0])-1].append([int(ll[1]),int(ll[2]),int(ll[3])])\n",
    "        \n",
    "        return self.rel\n",
    "        \n",
    "    \n",
    "    \n",
    "    def nextQuery(self):\n",
    "        query = {}\n",
    "        d = self.par.nextDocument()\n",
    "        query[\"id\"] = int(d.getId())\n",
    "        query[\"text\"] = d.get(\"text\")\n",
    "        query['answer'] = d.get('answer')\n",
    "        query['pertinent'] = self.rel[query[\"id\"]-1]\n",
    "        return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '  1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)   ',\n",
       " 'id': 1,\n",
       " 'pertinent': [[1410, 0, 0],\n",
       "  [1572, 0, 0],\n",
       "  [1605, 0, 0],\n",
       "  [2020, 0, 0],\n",
       "  [2358, 0, 0]],\n",
       " 'text': '  What articles exist which deal with TSS (Time Sharing System), an operating system for IBM computers?'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = QueryParser()\n",
    "a = q.nextQuery()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      " \n",
      "  \n",
      "   1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)    \n",
      "  \n",
      "   What articles exist which deal with TSS (Time Sharing System), an operating system for IBM computers?\n",
      "id=1\n",
      " \n",
      "  \n",
      "   1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)    \n",
      "  \n",
      "   What articles exist which deal with TSS (Time Sharing System), an operating system for IBM computers?\n",
      "{'from': '/home/melki/Documents/cours/RI/TP1/cacm/cacm.qry;0;169', 'author': '', 'text': '  What articles exist which deal with TSS (Time Sharing System), an operating system for IBM computers?', 'title': '', 'answer': '  1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)   ', 'keywords': ''}\n"
     ]
    }
   ],
   "source": [
    "print a.getId()\n",
    "print a.getText()\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IRList():\n",
    "    \n",
    "    __init__(self, query, lDocs):\n",
    "        self.query=query\n",
    "        self.lDocs=lDocs\n",
    "        \n",
    "class EvalMeasure():\n",
    "    \n",
    "    __init__(self):\n",
    "        print('init...')\n",
    "        \n",
    "    def eval(l):\n",
    "        print('undefined...')\n",
    "        \n",
    "class PrecisionRappelMeasure(EvalMeasure):\n",
    "    \n",
    "    def eval(l, nbLevels=10):\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
