{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "from ParserCACM import *\n",
    "from IndexerQuery import *\n",
    "from porter import *\n",
    "from copy import *\n",
    "from nltk.corpus import stopwords\n",
    "from TextRepresenter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processed collections \n",
    "collectionPath = 'data/cacm/cacm.txt'\n",
    "collectionPath2 = 'data/cisi/cisi.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1\n",
      " Preliminary Report-International Algebraic Language \n",
      "  Perlis, A. J. Samelson,K. \n",
      "  \n",
      " \n",
      "{'from': '/home/mcrilo33/Master/Master2/RI/TP1/data/cacm/cacm.txt;0;402', 'links': '100;123;164;205;210;214;1982;398;642;669;165;196;196;1273;1883;324;43;53;91;410;3184;', 'author': ' Perlis, A. J. Samelson,K.', 'text': '', 'title': ' Preliminary Report-International Algebraic Language', 'keywords': ''}\n"
     ]
    }
   ],
   "source": [
    "parser = ParserCACM()\n",
    "parser.initFile(collectionPath)\n",
    "docExample = parser.nextDocument()\n",
    "print(docExample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Indexer(object):\n",
    "    '''Build an Index from a Collection'''\n",
    "    \n",
    "    def __init__(\n",
    "        self, collectionPath,\n",
    "        parser,\n",
    "        fromCol=\"\",\n",
    "        repPath=\"\",\n",
    "        repIndexPath=\"\",\n",
    "        repInvPath=\"\",\n",
    "        repInvIndexPath=\"\",\n",
    "        repInvFromAllPath=\"\",\n",
    "        linkPath=\"\",\n",
    "        linkIndexPath=\"\"\n",
    "    ):\n",
    "        \n",
    "        # parser is a Parser object\n",
    "        self.parser = parser\n",
    "                 \n",
    "        # collectionPath is a String object\n",
    "        self.collectionPath = collectionPath\n",
    "        end = re.search(r'\\..*?$', collectionPath).group(0)\n",
    "                 \n",
    "        # Path names\n",
    "        if repPath==\"\":\n",
    "            self.repPath = \\\n",
    "                re.sub(r'\\..*$', 'Rep'+end, self.collectionPath)\n",
    "        else:\n",
    "            self.repPath = repPath\n",
    "        if fromCol==\"\":\n",
    "            self.fromCol = \\\n",
    "                re.sub(r'\\..*$', 'Index'+end, self.collectionPath)\n",
    "        else:\n",
    "            self.fromCol = fromCol\n",
    "        if repIndexPath==\"\":\n",
    "            self.repIndexPath = \\\n",
    "                re.sub(r'\\..*$', 'Index'+end, self.repPath)\n",
    "        else:\n",
    "            self.repIndexPath = repindexPath\n",
    "        if repInvIndexPath==\"\":\n",
    "            self.repInvIndexPath = \\\n",
    "                re.sub(r'\\..*$', 'InvIndex'+end, self.repPath)\n",
    "        else:\n",
    "            self.repInvIndexPath = repInvIndexPath\n",
    "        if repInvFromAllPath==\"\":\n",
    "            self.repInvFromAllPath = \\\n",
    "                re.sub(r'\\..*$', 'InvFromAll'+end, self.repPath)\n",
    "        else:\n",
    "            self.repInvFromAllPath = repInvFromAllPath\n",
    "        if repInvPath==\"\":\n",
    "            self.repInvPath = re.sub(r'\\..*$', 'Inv'+end, self.repPath)\n",
    "        else:\n",
    "            self.repInvPath\n",
    "        if linkPath==\"\":\n",
    "            self.linkPath = re.sub(r'\\..*$', 'Link'+end, self.collectionPath)\n",
    "        else:\n",
    "            self.linkPath\n",
    "        if linkIndexPath==\"\":\n",
    "            self.linkIndexPath = re.sub(r'\\..*$', 'LinkIndex'+end, self.collectionPath)\n",
    "        else:\n",
    "            self.linkIndexPath\n",
    "        \n",
    "        # Loads Hashtables if they exist\n",
    "        if os.path.isfile(self.repIndexPath):\n",
    "            repIndexFile = open(self.repIndexPath)\n",
    "            self.index = pickle.load(repIndexFile)\n",
    "            repIndexFile.close()\n",
    "        else:\n",
    "            self.index = {}\n",
    "        if os.path.isfile(self.fromCol):\n",
    "            fromColFile = open(self.fromCol)\n",
    "            self.indexFromCol = pickle.load(fromColFile)\n",
    "            fromColFile.close()\n",
    "        else:\n",
    "            self.indexFromCol = {}\n",
    "        if os.path.isfile(self.repInvIndexPath):\n",
    "            repInvIndexFile = open(self.repInvIndexPath)\n",
    "            self.invIndex = pickle.load(repInvIndexFile)\n",
    "            repInvIndexFile.close()\n",
    "        else:\n",
    "            self.invIndex = {}\n",
    "        if os.path.isfile(self.repInvFromAllPath):\n",
    "            repInvFromAllFile = open(self.repInvFromAllPath)\n",
    "            self.repInvFromAll = pickle.load(repInvFromAllFile)\n",
    "            repInvFromAllFile.close()\n",
    "        else:\n",
    "            self.repInvFromAll = {}\n",
    "        if os.path.isfile(self.linkIndexPath):\n",
    "            linkIndexFile = open(self.linkIndexPath)\n",
    "            self.linkIndex = pickle.load(linkIndexFile)\n",
    "            linkIndexFile.close()\n",
    "        else:\n",
    "            self.linkIndex = {}\n",
    "            \n",
    "        self.elements = {} # elements in self for optimisation reasons\n",
    "        \n",
    "    def __filters(self, doc):\n",
    "        '''Filters applied to each document of the collection'''\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def __getData(self, rep, index, id):\n",
    "        '''Return Something frequencies from a rep and his index at id==id'''\n",
    "        \n",
    "        id = str(id)\n",
    "        \n",
    "        if index=={}:\n",
    "            raise ValueError('Index undefined')\n",
    "        if not(os.path.isfile(rep)):\n",
    "            raise ValueError('Rep file does no exist')\n",
    "        if not(id in index):\n",
    "            raise ValueError('Bad Identifier')\n",
    "             \n",
    "        pos = index[id]\n",
    "        repFile = open(rep, 'r')\n",
    "        repFile.seek(pos[0])\n",
    "        rep = repFile.read(pos[1])\n",
    "        repFile.close()\n",
    "        \n",
    "        return rep\n",
    "        \n",
    "    def __freqFromData(self, data):\n",
    "    \n",
    "        freq = {}\n",
    "        total = 0\n",
    "        rep = data.split(':')\n",
    "        \n",
    "        for i in range(0, len(rep), 2):\n",
    "            added = int(rep[i+1])\n",
    "            freq[rep[i]] = added\n",
    "            total += added\n",
    "        freq[-1] = total\n",
    "        \n",
    "        return freq\n",
    "    \n",
    "    def __updatePosElements(self, doc):\n",
    "        '''Update pos and size of each element in inv index'''\n",
    "        \n",
    "        elements = self.elementsFromDoc(doc)\n",
    "        id = len(doc.getId())\n",
    "        \n",
    "        for element in elements:\n",
    "            \n",
    "            added = id+len(str(elements[element]))+2\n",
    "            if element in self.elements:\n",
    "                self.elements[element] += added\n",
    "            else:\n",
    "                self.elements[element] = added-1\n",
    "            \n",
    "        return self.elements\n",
    "    \n",
    "    def elementsFromDoc(self, doc):\n",
    "        '''Return an hashtable of the count of each element in a doc'''\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "    \n",
    "    def getEfFromDoc(self, id):\n",
    "        '''Return the element frequencies of a doc with identifier==id'''\n",
    "        \n",
    "        data = self.__getData(self.repPath, self.index, str(id))\n",
    "        return self.__freqFromData(data)\n",
    "            \n",
    "    def getDfFromEl(self, element):\n",
    "        '''Return the document frequencies of an element'''\n",
    "        \n",
    "        data = self.__getData(self.repInvPath, self.invIndex, str(element))\n",
    "        return self.__freqFromData(data)\n",
    "        \n",
    "    def getLinkFromDoc(self, id):\n",
    "        '''Return the links of a document'''\n",
    "        \n",
    "        return self.__getData(self.linkPath, self.linkIndex, str(id)).split(\";\")\n",
    "    \n",
    "    def getStrFromDoc(self, id):\n",
    "        '''Return the string of a doc with identifier==id in Col'''\n",
    "        \n",
    "        return self.__getData(self.collectionPath, self.indexFromCol, str(id))\n",
    "    \n",
    "    def getObjFromDoc(self, id):\n",
    "        '''Return the object of a doc with identifier==id in Col'''\n",
    "        \n",
    "        return self.parser.getDocument(self.getStrFromDoc(id))\n",
    "    \n",
    "    def createIndex(self):\n",
    "        \n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        posCol = self.parser.file.tell()\n",
    "        doc = self.parser.nextDocument()\n",
    "        self.indexFromCol = {}\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            posCol2 = self.parser.file.tell()\n",
    "        \n",
    "            if self.__filters(doc)==True:\n",
    "                # Get pos in col and size of current doc\n",
    "                self.indexFromCol[doc.getId()] = [posCol, posCol2-posCol]\n",
    "                \n",
    "            doc = self.parser.nextDocument()\n",
    "            posCol = posCol2\n",
    "            \n",
    "        # Indexes'hashtable of doc in col\n",
    "        fromCol = open(self.fromCol, \"w\")\n",
    "        pickle.dump(self.indexFromCol, fromCol)\n",
    "        \n",
    "        fromCol.close()\n",
    "        \n",
    "    def createRepIndex(self):\n",
    "            \n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        posCol = self.parser.file.tell()\n",
    "        doc = self.parser.nextDocument()\n",
    "        repFile = open(self.repPath, \"w\")\n",
    "        pos = 0\n",
    "        self.index = {}\n",
    "        self.indexFromCol = {}\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            posCol2 = self.parser.file.tell()\n",
    "            \n",
    "            if self.__filters(doc)==True:\n",
    "                # Get rep of current doc\n",
    "                elements = self.elementsFromDoc(doc)\n",
    "                toWrite = ''\n",
    "                for element in elements:\n",
    "                    toWrite += ':'+element+':'+str(elements[element])\n",
    "                toWrite = toWrite[1:]\n",
    "                # Get pos in index and size of current rep\n",
    "                self.index[doc.getId()] = [pos, len(toWrite)]\n",
    "                # Get pos in col and size of current doc\n",
    "                self.indexFromCol[doc.getId()] = [posCol, posCol2-posCol]\n",
    "                \n",
    "                repFile.write(toWrite)\n",
    "                pos += len(toWrite)\n",
    "                \n",
    "            doc = self.parser.nextDocument()\n",
    "            posCol = posCol2\n",
    "            \n",
    "        repFile.close()\n",
    "        \n",
    "        # Indexes'hashtable of rep\n",
    "        repIndexFile = open(self.repIndexPath, \"w\")\n",
    "        pickle.dump(self.index, repIndexFile)\n",
    "        # Indexes'hashtable of doc in col\n",
    "        fromCol = open(self.fromCol, \"w\")\n",
    "        pickle.dump(self.indexFromCol, fromCol)\n",
    "        \n",
    "        repIndexFile.close()\n",
    "        fromCol.close()\n",
    "        \n",
    "    def createRepInvIndex(self):\n",
    "        \n",
    "        # First pass\n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        doc = self.parser.nextDocument()\n",
    "        self.elements = {}\n",
    "        self.invIndex = {}\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            if self.__filters(doc)==True:\n",
    "                # Updates pos and size of each element in inv index\n",
    "                self.__updatePosElements(doc)\n",
    "                \n",
    "            doc = self.parser.nextDocument()\n",
    "            \n",
    "        # Get pos and size of each elements from there size in inv index\n",
    "        cumsum = 0\n",
    "        for element in self.elements:\n",
    "            tmp = self.elements[element]\n",
    "            self.elements[element] = [cumsum, tmp]\n",
    "            cumsum += tmp\n",
    "\n",
    "        # Indexes'hashtable of elements in inv index\n",
    "        for element in self.elements:\n",
    "            self.invIndex[element] = self.elements[element]\n",
    "        repInvIndexFile = open(self.repInvIndexPath, \"w\")\n",
    "        pickle.dump(self.invIndex, repInvIndexFile)\n",
    "        repInvIndexFile.close()\n",
    "        \n",
    "        # Second pass\n",
    "        repInvFile = open(self.repInvPath, \"w\")\n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        doc = self.parser.nextDocument()\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            if self.__filters(doc)==True:\n",
    "                elements = self.elementsFromDoc(doc)\n",
    "                toWrite = ''\n",
    "                for element in elements:\n",
    "                    toWrite = doc.getId()+':'+str(elements[element])+':'\n",
    "                    repInvFile.seek(self.elements[element][0])\n",
    "                    if (self.elements[element][1]-len(toWrite)) < 0:\n",
    "                        toWrite = toWrite[:-1]\n",
    "                    repInvFile.write(toWrite)\n",
    "                    self.elements[element][0] += len(toWrite)\n",
    "                    self.elements[element][1] -= len(toWrite)\n",
    "                    \n",
    "            doc = self.parser.nextDocument()\n",
    "        \n",
    "        repInvIndexFile = open(self.repInvIndexPath)\n",
    "        self.invIndex = pickle.load(repInvIndexFile)\n",
    "        repInvIndexFile.close()\n",
    "        repInvFile.close()\n",
    "        \n",
    "    def createRepInvFromAll(self):\n",
    "        \n",
    "        if self.index == {}:\n",
    "            raise ValueError('Rep index undefined')\n",
    "            \n",
    "        if self.invIndex == {}:\n",
    "            raise ValueError('Rep invIndex undefined')\n",
    "            \n",
    "        self.repInvFromAll = {}\n",
    "        \n",
    "        for element in self.invIndex:\n",
    "            docs = self.getDfFromEl(element)\n",
    "            docs.pop(-1)\n",
    "            self.repInvFromAll[element] = np.sum([docs[doc] for doc in docs])\n",
    "        \n",
    "        self.repInvFromAll[-1] = 0\n",
    "        for id in self.index:\n",
    "            freq = self.getEfFromDoc(id)\n",
    "            self.repInvFromAll[-1] += freq[-1]\n",
    "                \n",
    "        # Indexes'hashtable of doc in col\n",
    "        repInvFromAllFile = open(self.repInvFromAllPath, \"w\")\n",
    "        pickle.dump(self.repInvFromAll, repInvFromAllFile)\n",
    "\n",
    "        repInvFromAllFile.close()\n",
    "                \n",
    "    def createLinkIndex(self):\n",
    "        \n",
    "        if self.index == {}:\n",
    "            raise ValueError('Rep index undefined')\n",
    "            \n",
    "        if self.indexFromCol == {}:\n",
    "            raise ValueError('Rep invIndex undefined')\n",
    "        \n",
    "        self.linkIndex = {}\n",
    "        \n",
    "        linkFile = open(self.linkPath, \"w\")\n",
    "        pos = linkFile.tell()\n",
    "        \n",
    "        for id in self.index:\n",
    "            \n",
    "            doc = self.getObjFromDoc(id)\n",
    "            links = doc.get('links')[:-1]\n",
    "            linkFile.write(links)\n",
    "            pos2 = linkFile.tell()\n",
    "            self.linkIndex[id] = [pos, pos2-pos]\n",
    "            pos = pos2\n",
    "            \n",
    "        linkFile.close()\n",
    "        \n",
    "        linkIndexFile = open(self.linkIndexPath, \"w\")\n",
    "        pickle.dump(self.linkIndex, linkIndexFile)\n",
    "        linkIndexFile.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IndexerCACM(Indexer):\n",
    "    \n",
    "    def __init__(self, collectionPath, parser):\n",
    "        \n",
    "        Indexer.__init__(self, collectionPath, parser)\n",
    "        \n",
    "    def elementsFromDoc(self, doc):\n",
    "        \n",
    "        elements = {}\n",
    "        text = doc.getText()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        # preprocessing\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'(!|#|\"|%|\\$|\\'|&|\\)|\\(|\\+|\\*|(^| )(-( |$))+|,|/|\\.|;|:|=|<|\\?|>|@|[|]|\\|_|^|`|{|}|\\||~)', ' ', text)\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub(r'(^| )(\\w($| ))+', ' ', text)\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        \n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "        return stemmer.getTextRepresentation(text)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructions of Index and Inversed Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.IndexerCACM object at 0x7f5200e5f310>\n"
     ]
    }
   ],
   "source": [
    "indexer = IndexerCACM(collectionPath, ParserCACM())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "indexer.createRepIndex()\n",
    "indexer.createRepInvIndex()\n",
    "indexer.createRepInvFromAll()\n",
    "indexer.createLinkIndex()\n",
    "\n",
    "print(indexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get string from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 111\n",
      ".T\n",
      "On Programming the Numerical Solution of Polynomial Equations\n",
      ".W\n",
      "Numerical techniques are presented for computing\n",
      "the roots of polynomial equations.  By applying \n",
      "the recommended scaling and inversion rules, the basic\n",
      "Bairstow and Newton-Raphson iterative techniques \n",
      "can be applied with great reliability.  Both a high degree\n",
      "of accuracy and rapid convergence are realized. \n",
      " Numerical examples are shown to illustrate the pitfalls\n",
      "and to show how these are circumvented by application \n",
      "of the recommended procedures.\n",
      ".B\n",
      "CACM December, 1960\n",
      ".A\n",
      "Ellenberger, K. W.\n",
      ".N\n",
      "CA601205 JB March 20, 1978  6:41 PM\n",
      ".X\n",
      "111\t5\t111\n",
      "111\t5\t111\n",
      "111\t5\t111\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(indexer.getStrFromDoc(111))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get obj from Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accelerating Convergence of Iterative Processes \n",
      "  Wegstein, J. H. \n",
      "  \n",
      "  A technique is discussed which, when applied to an iterative procedure for the solution of an equation, accelerates the rate of convergence if the iteration converges and induces convergence if the iteration diverges.  An illustrative example is given.\n"
     ]
    }
   ],
   "source": [
    "obj = indexer.getObjFromDoc(20)\n",
    "print(obj.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get element frequencies from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acceler': 1, 'techniqu': 1, 'process': 1, 'appli': 1, 'induc': 1, 'accelerat': 1, 'solut': 1, 'wegstein': 1, 'procedur': 1, 'converg': 4, 'rate': 1, 'exampl': 1, 'iter': 4, 'illustr': 1, 'diverg': 1, 'discuss': 1, -1: 23, 'equat': 1}\n"
     ]
    }
   ],
   "source": [
    "print(indexer.getEfFromDoc(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get document frequencies from element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3715': 1, '4003': 2, '3520': 2, '3712': 2, '3496': 2, '3571': 1, '3494': 1, '3495': 1, '3492': 1, '3491': 1, '3320': 1, '3322': 1, '3326': 1, '3656': 1, '3437': 1, '3652': 1, '3808': 1, '3554': 1, '20': 1, '3551': 1, '3250': 2, '3794': 1, '3797': 1, '3254': 2, '3255': 1, '4143': 1, '4199': 1, '3805': 1, '3853': 1, '3999': 1, '3750': 1, '3996': 2, '4138': 1, '3723': 1, '3993': 1, '3928': 1, '3489': 1, '3761': 2, '3762': 1, '3837': 2, '3764': 1, '3938': 1, '3767': 1, '3480': 1, '3936': 1, '3838': 1, '3930': 1, '3486': 1, '3401': 1, '3332': 1, '3817': 1, '3407': 1, '4070': 1, '4039': 1, '4186': 1, '3642': 1, '4178': 2, '3562': 1, '4026': 1, '3248': 1, '3566': 1, '3883': 1, '3564': 1, '3243': 1, '3241': 1, '3569': 1, '4024': 1, '3245': 1, '3814': 1, '3444': 3, '4180': 2, '3568': 1, '3948': 1, '3772': 1, '3680': 1, '3777': 1, '3410': 1, '3821': 1, '3820': 1, '3687': 1, '3942': 1, '3649': 1, '3709': 1, '3947': 1, '4109': 1, '3273': 1, '3308': 1, '4108': 1, '3672': 1, '3661': 1, '4200': 1, '3677': 1, '3278': 1, '3301': 1, '3386': 1, '3387': 1, '3823': 1, '4128': 1, '3471': 1, '3380': 2, '3381': 1, '4123': 1, '4122': 2, '3576': 1, '3478': 1, '3573': 2, '4124': 1, '4196': 2, '4033': 1, '4063': 1, '4095': 2, '4016': 1, '3822': 1, '3958': 1, '3584': 1, '3585': 2, '3586': 1, '3662': 1, '3746': 1, '3747': 1, '3744': 1, '4140': 1, '4053': 1, '4139': 1, '3263': 1, '3518': 1, '4112': 2, '3264': 1, '3269': 1, '3310': 1, '4203': 1, '3467': 1, '3509': 1, '3464': 1, '3395': 3, '3462': 2, '4051': 1, '3399': 1, '3502': 1, '3503': 1, '3505': 2, '3469': 1, '4058': 3, '3681': 1, '644': 1, '3691': 1, '4147': 1, '4113': 2, '4189': 1, '4103': 1, '3591': 1, '3613': 2, '3614': 1, '3596': 2, '4151': 1, '3826': 2, '3751': 1, '3619': 1, '3599': 1, '3598': 1, '4175': 2, '3802': 2, '3749': 1, '3944': 1, '4104': 1, '3294': 1, '3295': 1, '3296': 1, '3290': 1, '3776': 1, '3453': 1, '3450': 1, '3451': 1, '3457': 1, '3934': 1, '4065': 1, '3513': 1, '3512': 1, '4068': 1, '3459': 2, '3360': 1, '3696': 1, '3863': 1, '3898': 1, '3893': 1, '3884': 1, '3391': 1, '3694': 1, '3870': 1, '3871': 1, '3608': 1, '3875': 2, '4181': 1, '3527': 1, '3525': 2, '3728': 3, '3289': 3, '227': 1, '3286': 1, '93': 1, '4042': 2, '3528': 1, '3280': 1, '11': 1, '3206': 1, '4176': 1, '3994': 1, '3449': 1, '14': 1, '3379': 1, '3378': 1, '3376': 2, '3447': 1, '3446': 1, '3373': 1, '3372': 1, '1180': 1, '3684': 1, '3966': 1, '3967': 1, '3960': 1, '3968': 1, '4080': 2, '4082': 1, '3868': 2, '3901': 2, '3879': 1, '3636': 1, '3548': 1, '3634': 1, '3908': 1, '3633': 1, '3865': 1, '3549': 1, '3534': 1, '3673': 1, '3737': 1, '3538': 1, '3222': 1, '3731': 1, '3783': 1, '3236': 1, '3342': 2, '3340': 1, '3833': 1, '4005': 2, '3345': 1, '4120': 3, '3769': 2, '4173': 1, '3978': 1, '3629': 4, '4092': 1, '3911': 2, '3623': 1, '3625': 3, '3624': 1, '3919': 1, '3663': 1, '3354': 1, '3356': 1, '3350': 1, '3700': 1, '3707': 1, '3704': 2, '4152': 1, '3545': 1, '3781': 1, '3786': 1, '3228': 1, '3543': 1, '3423': 1, '3227': 1, '3789': 1, '3221': 1, '3220': 1, '3424': 1, '4014': 1, '3882': 2, '3988': 1, '3989': 1, '4046': 1, '3985': 1, '4002': 3, -1: 343}\n"
     ]
    }
   ],
   "source": [
    "print(indexer.getDfFromEl('wegstein'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Queries Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'56': [11573, 146], '54': [11134, 290], '42': [8905, 189], '48': [10140, 285], '43': [9094, 212], '60': [12677, 325], '61': [13002, 258], '62': [13260, 138], '63': [13398, 143], '64': [13541, 144], '49': [10425, 120], '52': [10728, 84], '53': [10812, 322], '24': [3968, 87], '25': [4055, 104], '26': [4159, 110], '27': [4269, 102], '20': [3323, 126], '21': [3449, 186], '22': [3635, 225], '23': [3860, 108], '46': [9709, 198], '47': [9907, 233], '44': [9306, 136], '45': [9442, 267], '28': [4371, 263], '29': [4634, 165], '40': [8091, 328], '41': [8419, 486], '1': [0, 169], '3': [347, 150], '2': [169, 178], '5': [918, 294], '4': [497, 421], '7': [1415, 311], '6': [1212, 203], '9': [1871, 149], '8': [1726, 145], '51': [10655, 73], '39': [7811, 280], '38': [7529, 282], '59': [12422, 255], '58': [12122, 300], '11': [2147, 96], '10': [2020, 127], '13': [2322, 94], '12': [2243, 79], '15': [2596, 192], '14': [2416, 180], '17': [2960, 108], '16': [2788, 172], '19': [3243, 80], '18': [3068, 175], '31': [4971, 480], '30': [4799, 172], '37': [7092, 437], '36': [6959, 133], '35': [6677, 282], '34': [6426, 251], '33': [5805, 621], '55': [11424, 149], '32': [5451, 354], '57': [11719, 403], '50': [10545, 110]}\n"
     ]
    }
   ],
   "source": [
    "queriesPath = 'data/cacm/cacm.qry'\n",
    "parser = ParserCACM()\n",
    "queriesIndexer = IndexerCACM(queriesPath, ParserCACM())\n",
    "\n",
    "# If Index isn't already builded\n",
    "queriesIndexer.createRepIndex()\n",
    "print(queriesIndexer.indexFromCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RelevantParser(Parser):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        Parser.__init__(self, '')\n",
    "        self.curId = None\n",
    "    \n",
    "    def nextDocument(self):\n",
    "        \n",
    "        if self.curId==None:\n",
    "            self.curLine = self.file.readline()\n",
    "            if self.curLine!=None:\n",
    "                self.curId = ((self.curLine).split())[0]\n",
    "            \n",
    "        id = self.curId\n",
    "        text = ''\n",
    "        \n",
    "        while(id==self.curId and self.curLine!=''):\n",
    "            text += self.curLine\n",
    "            pos = self.file.tell()\n",
    "            self.curLine = self.file.readline()\n",
    "            if self.curLine!='':\n",
    "                self.curId = ((self.curLine).split())[0]\n",
    "        if self.curLine!='':\n",
    "            self.file.seek(pos)\n",
    "        \n",
    "        if text=='':\n",
    "            return None\n",
    "        \n",
    "        return self.getDocument(text)\n",
    "        \n",
    "    def getDocument(self, text):\n",
    "        \n",
    "        tab = \\\n",
    "        [\n",
    "            [str(int((i.split())[1])), int((i.split())[2]), int((i.split())[3])] \\\n",
    "            for i in text.split('\\n')[:-1] \\\n",
    "        ]\n",
    "        identifier = str(int(text.split()[0]))\n",
    "        \n",
    "        return Document(identifier, others={'tab': tab})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevantPath = 'data/cacm/cacm.rel'\n",
    "relevantIndexer = Indexer(relevantPath, RelevantParser())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "relevantIndexer.createIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'42': [6612, 252], '48': [7872, 144], '43': [6864, 492], '60': [9000, 324], '61': [9324, 372], '62': [9696, 96], '63': [9792, 144], '64': [9936, 12], '49': [8016, 96], '24': [3712, 169], '25': [3881, 663], '26': [4544, 390], '27': [4934, 377], '20': [3267, 36], '21': [3303, 143], '22': [3446, 214], '23': [3660, 52], '44': [7356, 204], '45': [7560, 312], '28': [5311, 64], '29': [5375, 247], '40': [6492, 120], '1': [0, 65], '3': [104, 78], '2': [65, 39], '5': [338, 101], '4': [182, 156], '7': [478, 364], '6': [439, 39], '9': [879, 113], '8': [842, 37], '39': [6348, 144], '38': [6156, 192], '59': [8484, 516], '58': [8124, 360], '11': [1447, 247], '10': [992, 455], '13': [1759, 143], '12': [1694, 65], '15': [2450, 126], '14': [1902, 548], '17': [2784, 208], '16': [2576, 208], '19': [3135, 132], '18': [2992, 143], '31': [5674, 26], '30': [5622, 52], '37': [6012, 144], '36': [5752, 260], '33': [5739, 13], '32': [5700, 39], '57': [8112, 12]}\n"
     ]
    }
   ],
   "source": [
    "print(relevantIndexer.indexFromCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "\n",
    "    def __init__(self, id, text=\"\", el=None, relevants=None):\n",
    "        \n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.el = el\n",
    "        self.relevants = relevants\n",
    "        \n",
    "def query(id, queriesIndexer, relevantIndexer):\n",
    "    \n",
    "    id = str(id)\n",
    "    text = queriesIndexer.getObjFromDoc(id).getText()\n",
    "    el = queriesIndexer.getEfFromDoc(id)\n",
    "    relevants = relevantIndexer.getObjFromDoc(id).get('tab')\n",
    "    \n",
    "    return Query(id, text, el, relevants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Id : ', '5')\n",
      "('Text : ', \" \\n  \\n  \\n   I'd like papers on design and implementation of editing interfaces, window-managers, command interpreters, etc.  The essential issues are human interface design, with views on improvements to user efficiency, effectiveness and satisfaction.\")\n",
      "('Elements : ', {-1: 20, 'effici': 1, 'satisfact': 1, 'essenti': 1, 'command': 1, 'effect': 1, 'issu': 1, 'edit': 1, 'window': 1, 'paper': 1, 'design': 2, 'user': 1, 'human': 1, 'interfac': 2, 'improv': 1, 'implement': 1, 'manag': 1, 'interpret': 1, 'view': 1})\n",
      "('Relevants : ', [['756', 0, 0], ['1307', 0, 0], ['1502', 0, 0], ['2035', 0, 0], ['2299', 0, 0], ['2399', 0, 0], ['2501', 0, 0], ['2820', 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "q = query(5, queriesIndexer, relevantIndexer)\n",
    "print('Id : ', q.id)\n",
    "print('Text : ', q.text)\n",
    "print('Elements : ', q.el)\n",
    "print('Relevants : ', q.relevants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
