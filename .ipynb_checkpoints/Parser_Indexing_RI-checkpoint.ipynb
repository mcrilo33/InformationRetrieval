{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "from ParserCACM import *\n",
    "from porter import *\n",
    "from copy import *\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processed collections \n",
    "collectionPath = 'data/cacm/cacm.txt'\n",
    "collectionPath2 = 'data/cisi/cisi.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1\n",
      " Preliminary Report-International Algebraic Language \n",
      "  Perlis, A. J. Samelson,K. \n",
      "  CA581203 JB March 22, 1978  8:28 PM \n",
      "  \n",
      " \n",
      "{'from': '/home/mcrilo33/Master/Master2/RI/TP1/data/cacm/cacm.txt;0;402', 'links': '100;123;164;205;210;214;1982;398;642;669;165;196;196;1273;1883;324;43;53;91;410;3184;', 'author': ' Perlis, A. J. Samelson,K.', 'text': '', 'title': ' Preliminary Report-International Algebraic Language', 'answer': ' CA581203 JB March 22, 1978  8:28 PM', 'keywords': ''}\n"
     ]
    }
   ],
   "source": [
    "parser = ParserCACM()\n",
    "parser.initFile(collectionPath)\n",
    "docExample = parser.nextDocument()\n",
    "print(docExample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Indexer(object):\n",
    "    '''Build an Index from a Collection'''\n",
    "    \n",
    "    def __init__(\n",
    "        self, collectionPath,\n",
    "        parser,\n",
    "        fromCol=\"\",\n",
    "        repPath=\"\",\n",
    "        repIndexPath=\"\",\n",
    "        repInvPath=\"\",\n",
    "        repInvIndexPath=\"\",\n",
    "        repInvFromAllPath=\"\",\n",
    "        repInvIndexFromAllPath=\"\"\n",
    "    ):\n",
    "        \n",
    "        # parser is a Parser object\n",
    "        self.parser = parser\n",
    "                 \n",
    "        # collectionPath is a String object\n",
    "        self.collectionPath = collectionPath\n",
    "        end = re.search(r'\\..*?$', collectionPath).group(0)\n",
    "                 \n",
    "        # Path names\n",
    "        if repPath==\"\":\n",
    "            self.repPath = \\\n",
    "                re.sub(r'\\..*$', 'Rep'+end, self.collectionPath)\n",
    "        else:\n",
    "            self.repPath = repPath\n",
    "        if fromCol==\"\":\n",
    "            self.fromCol = \\\n",
    "                re.sub(r'\\..*$', 'Index'+end, self.collectionPath)\n",
    "        else:\n",
    "            self.fromCol = fromCol\n",
    "        if repIndexPath==\"\":\n",
    "            self.repIndexPath = \\\n",
    "                re.sub(r'\\..*$', 'Index'+end, self.repPath)\n",
    "        else:\n",
    "            self.repIndexPath = repindexPath\n",
    "        if repInvIndexPath==\"\":\n",
    "            self.repInvIndexPath = \\\n",
    "                re.sub(r'\\..*$', 'InvIndex'+end, self.repPath)\n",
    "        else:\n",
    "            self.repInvIndexPath = repInvIndexPath\n",
    "        if repInvFromAllPath==\"\":\n",
    "            self.repInvFromAllPath = \\\n",
    "                re.sub(r'\\..*$', 'InvFromAll'+end, self.repPath)\n",
    "        else:\n",
    "            self.repInvFromAllPath = repInvFromAllPath\n",
    "        if repInvIndexFromAllPath==\"\":\n",
    "            self.repInvIndexFromAllPath = \\\n",
    "                re.sub(r'\\..*$', 'InvIndexFromAll'+end, self.repPath)\n",
    "        else:\n",
    "            self.repInvIndexFromAllPath = repInvIndexFromAllPath\n",
    "        if repInvPath==\"\":\n",
    "            self.repInvPath = re.sub(r'\\..*$', 'Inv'+end, self.repPath)\n",
    "        else:\n",
    "            self.repInvPath\n",
    "        \n",
    "        # Loads Hashtables if they exist\n",
    "        if os.path.isfile(self.repIndexPath):\n",
    "            repIndexFile = open(self.repIndexPath)\n",
    "            self.index = pickle.load(repIndexFile)\n",
    "            repIndexFile.close()\n",
    "        else:\n",
    "            self.index = {}\n",
    "        if os.path.isfile(self.fromCol):\n",
    "            fromColFile = open(self.fromCol)\n",
    "            self.indexFromCol = pickle.load(fromColFile)\n",
    "            fromColFile.close()\n",
    "        else:\n",
    "            self.indexFromCol = {}\n",
    "        if os.path.isfile(self.repInvIndexPath):\n",
    "            repInvIndexFile = open(self.repInvIndexPath)\n",
    "            self.invIndex = pickle.load(repInvIndexFile)\n",
    "            repInvIndexFile.close()\n",
    "        else:\n",
    "            self.invIndex = {}\n",
    "        if os.path.isfile(self.repInvIndexFromAllPath):\n",
    "            repInvIndexFromAllFile = open(self.repInvIndexFromAllPath)\n",
    "            self.invIndexFromAll = pickle.load(repInvIndexFromAllFile)\n",
    "            repInvIndexFromAllFile.close()\n",
    "        else:\n",
    "            self.InvIndexFromAll = {}\n",
    "            \n",
    "        self.elements = {} # elements in self for optimisation reasons\n",
    "        \n",
    "    def __filters(self, doc):\n",
    "        '''Filters applied to each document of the collection'''\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def __getData(self, rep, index, id):\n",
    "        '''Return Something frequencies from a rep and his index at id==id'''\n",
    "        \n",
    "        id = str(id)\n",
    "        \n",
    "        if index=={}:\n",
    "            raise ValueError('Index undefined')\n",
    "        if not(os.path.isfile(rep)):\n",
    "            raise ValueError('Rep file does no exist')\n",
    "        if not(id in index):\n",
    "            raise ValueError('Bad Identifier')\n",
    "             \n",
    "        pos = index[id]\n",
    "        repFile = open(rep, 'r')\n",
    "        repFile.seek(pos[0])\n",
    "        rep = repFile.read(pos[1])\n",
    "        repFile.close()\n",
    "        \n",
    "        return rep\n",
    "        \n",
    "    def __freqFromData(self, data):\n",
    "    \n",
    "        freq = {}\n",
    "        total = 0\n",
    "        rep = data.split(':')\n",
    "        \n",
    "        for i in range(0, len(rep), 2):\n",
    "            added = int(rep[i+1])\n",
    "            freq[rep[i]] = added\n",
    "            total += added\n",
    "        freq[-1] = total\n",
    "        \n",
    "        return freq\n",
    "    \n",
    "    def __updatePosElements(self, doc):\n",
    "        '''Update pos and size of each element in inv index'''\n",
    "        \n",
    "        elements = self.elementsFromDoc(doc)\n",
    "        id = len(doc.getId())\n",
    "        \n",
    "        for element in elements:\n",
    "            \n",
    "            added = id+len(str(elements[element]))+2\n",
    "            if element in self.elements:\n",
    "                self.elements[element] += added\n",
    "            else:\n",
    "                self.elements[element] = added-1\n",
    "            \n",
    "        return self.elements\n",
    "    \n",
    "    def elementsFromDoc(self, doc):\n",
    "        '''Return an hashtable of the count of each element in a doc'''\n",
    "        \n",
    "        raise ValueError('Abstract method')\n",
    "    \n",
    "    def getEfFromDoc(self, id):\n",
    "        '''Return the element frequencies of a doc with identifier==id'''\n",
    "        \n",
    "        data = self.__getData(self.repPath, self.index, str(id))\n",
    "        return self.__freqFromData(data)\n",
    "            \n",
    "    def getDfFromEl(self, element):\n",
    "        '''Return the document frequencies of an element'''\n",
    "        \n",
    "        data = self.__getData(self.repInvPath, self.invIndex, str(element))\n",
    "        return self.__freqFromData(data)\n",
    "        \n",
    "    def getStrFromDoc(self, id):\n",
    "        '''Return the string of a doc with identifier==id in Col'''\n",
    "        \n",
    "        return self.__getData(self.collectionPath, self.indexFromCol, str(id))\n",
    "    \n",
    "    def getObjFromDoc(self, id):\n",
    "        '''Return the object of a doc with identifier==id in Col'''\n",
    "        \n",
    "        return self.parser.getDocument(self.getStrFromDoc(id))\n",
    "    \n",
    "    def createIndex(self):\n",
    "        \n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        posCol = self.parser.file.tell()\n",
    "        doc = self.parser.nextDocument()\n",
    "        self.indexFromCol = {}\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            posCol2 = self.parser.file.tell()\n",
    "        \n",
    "            if self.__filters(doc)==True:\n",
    "                # Get pos in col and size of current doc\n",
    "                self.indexFromCol[doc.getId()] = [posCol, posCol2-posCol]\n",
    "                \n",
    "            doc = self.parser.nextDocument()\n",
    "            posCol = posCol2\n",
    "            \n",
    "        # Indexes'hashtable of doc in col\n",
    "        fromCol = open(self.fromCol, \"w\")\n",
    "        pickle.dump(self.indexFromCol, fromCol)\n",
    "        \n",
    "        fromCol.close()\n",
    "        \n",
    "    def createRepIndex(self):\n",
    "            \n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        posCol = self.parser.file.tell()\n",
    "        doc = self.parser.nextDocument()\n",
    "        repFile = open(self.repPath, \"w\")\n",
    "        pos = 0\n",
    "        self.index = {}\n",
    "        self.indexFromCol = {}\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            posCol2 = self.parser.file.tell()\n",
    "            \n",
    "            if self.__filters(doc)==True:\n",
    "                # Get rep of current doc\n",
    "                elements = self.elementsFromDoc(doc)\n",
    "                toWrite = ''\n",
    "                for element in elements:\n",
    "                    toWrite += ':'+element+':'+str(elements[element])\n",
    "                toWrite = toWrite[1:]\n",
    "                # Get pos in index and size of current rep\n",
    "                self.index[doc.getId()] = [pos, len(toWrite)]\n",
    "                # Get pos in col and size of current doc\n",
    "                self.indexFromCol[doc.getId()] = [posCol, posCol2-posCol]\n",
    "                \n",
    "                repFile.write(toWrite)\n",
    "                pos += len(toWrite)\n",
    "                \n",
    "            doc = self.parser.nextDocument()\n",
    "            posCol = posCol2\n",
    "            \n",
    "        repFile.close()\n",
    "        \n",
    "        # Indexes'hashtable of rep\n",
    "        repIndexFile = open(self.repIndexPath, \"w\")\n",
    "        pickle.dump(self.index, repIndexFile)\n",
    "        # Indexes'hashtable of doc in col\n",
    "        fromCol = open(self.fromCol, \"w\")\n",
    "        pickle.dump(self.indexFromCol, fromCol)\n",
    "        \n",
    "        repIndexFile.close()\n",
    "        fromCol.close()\n",
    "        \n",
    "    def createRepInvIndex(self):\n",
    "        \n",
    "        # First pass\n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        doc = self.parser.nextDocument()\n",
    "        self.elements = {}\n",
    "        self.invIndex = {}\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            if self.__filters(doc)==True:\n",
    "                # Updates pos and size of each element in inv index\n",
    "                self.__updatePosElements(doc)\n",
    "                \n",
    "            doc = self.parser.nextDocument()\n",
    "            \n",
    "        # Get pos and size of each elements from there size in inv index\n",
    "        cumsum = 0\n",
    "        for element in self.elements:\n",
    "            tmp = self.elements[element]\n",
    "            self.elements[element] = [cumsum, tmp]\n",
    "            cumsum += tmp\n",
    "\n",
    "        # Indexes'hashtable of elements in inv index\n",
    "        for element in self.elements:\n",
    "            self.invIndex[element] = self.elements[element]\n",
    "        repInvIndexFile = open(self.repInvIndexPath, \"w\")\n",
    "        pickle.dump(self.invIndex, repInvIndexFile)\n",
    "        repInvIndexFile.close()\n",
    "        \n",
    "        # Second pass\n",
    "        repInvFile = open(self.repInvPath, \"w\")\n",
    "        self.parser.initFile(self.collectionPath)\n",
    "        doc = self.parser.nextDocument()\n",
    "        \n",
    "        while doc!=None:\n",
    "            \n",
    "            if self.__filters(doc)==True:\n",
    "                elements = self.elementsFromDoc(doc)\n",
    "                toWrite = ''\n",
    "                for element in elements:\n",
    "                    toWrite = doc.getId()+':'+str(elements[element])+':'\n",
    "                    repInvFile.seek(self.elements[element][0])\n",
    "                    if (self.elements[element][1]-len(toWrite)) < 0:\n",
    "                        toWrite = toWrite[:-1]\n",
    "                    repInvFile.write(toWrite)\n",
    "                    self.elements[element][0] += len(toWrite)\n",
    "                    self.elements[element][1] -= len(toWrite)\n",
    "                    \n",
    "            doc = self.parser.nextDocument()\n",
    "        \n",
    "        repInvIndexFile = open(self.repInvIndexPath)\n",
    "        self.invIndex = pickle.load(repInvIndexFile)\n",
    "        repInvIndexFile.close()\n",
    "        repInvFile.close()\n",
    "        \n",
    "    def createRepInvIndexFromAll(self):\n",
    "        \n",
    "        if self.index == {}:\n",
    "            raise ValueError('Rep index undefined')\n",
    "            \n",
    "        if self.invIndex == {}:\n",
    "            raise ValueError('Rep invIndex undefined')\n",
    "            \n",
    "        self.invIndexFromAll = {}\n",
    "        repInvFromAll = {}\n",
    "        \n",
    "        for element in self.invIndex:\n",
    "            docs = self.getDfFromEl(element)\n",
    "            repInvFromAll[element] = np.sum([docs[doc] for doc in docs])\n",
    "        \n",
    "        repInvFromAll[-1] = 0\n",
    "        for id in self.index:\n",
    "            freq = self.getEfFromDoc(id)\n",
    "            repInvFromAll[-1] += freq[-1]\n",
    "                \n",
    "        repInvFromAllFile = open(self.repInvFromAllPath, \"w\")\n",
    "        pos = 0\n",
    "        for element in repInvFromAll:\n",
    "            toWrite = ''\n",
    "            toWrite += ':'+str(element)+':'+str(repInvFromAll[element])\n",
    "            toWrite = toWrite[1:]\n",
    "            # Get pos in index and size of current rep\n",
    "            self.invIndexFromAll[id] = [pos, len(toWrite)]\n",
    "\n",
    "            repInvFromAllFile.write(toWrite)\n",
    "            pos += len(toWrite)\n",
    "\n",
    "        repInvFromAllFile.close()\n",
    "\n",
    "        # Indexes'hashtable of doc in col\n",
    "        invIndexFromAllFile = open(self.repInvIndexFromAllPath, \"w\")\n",
    "        pickle.dump(self.invIndexFromAll, invIndexFromAllFile)\n",
    "\n",
    "        invIndexFromAllFile.close()\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IndexerCACM(Indexer):\n",
    "    \n",
    "    def __init__(self, collectionPath, parser):\n",
    "        \n",
    "        Indexer.__init__(self, collectionPath, parser)\n",
    "        \n",
    "    def elementsFromDoc(self, doc):\n",
    "        \n",
    "        elements = {}\n",
    "        text = doc.getText()\n",
    "        \n",
    "        # preprocessing\n",
    "        text = text.lower()\n",
    "        exclude = set(string.punctuation)\n",
    "        exclude.remove(\"-\")\n",
    "        text = ''.join(word for word in text if word not in exclude)\n",
    "        # removes digit and \\n\n",
    "        text = re.sub(r'\\d+|\\n', '', text)\n",
    "        # removes one letter words\n",
    "        text = re.sub(r'(^| )(\\w( |$))+', ' ', text)\n",
    "        text = text.split()\n",
    "        \n",
    "        for word in text:\n",
    "            word = stem(word)\n",
    "            if word in elements:\n",
    "                elements[word] += 1\n",
    "            else:\n",
    "                elements[word] = 1\n",
    "        \n",
    "        return elements\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructions of Index and Inversed Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.IndexerCACM object at 0x7f6eebbd8a90>\n"
     ]
    }
   ],
   "source": [
    "indexer = IndexerCACM(collectionPath, ParserCACM())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#indexer.createRepIndex()\n",
    "#indexer.createRepInvIndex()\n",
    "indexer.createRepInvIndexFromAll()\n",
    "\n",
    "print(indexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get string from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 20\n",
      ".T\n",
      "Accelerating Convergence of Iterative Processes\n",
      ".W\n",
      "A technique is discussed which, when applied\n",
      "to an iterative procedure for the solution of\n",
      "an equation, accelerates the rate of convergence if\n",
      "the iteration converges and induces convergence if\n",
      "the iteration diverges.  An illustrative example is given.\n",
      ".B\n",
      "CACM June, 1958\n",
      ".A\n",
      "Wegstein, J. H.\n",
      ".N\n",
      "CA580602 JB March 22, 1978  9:09 PM\n",
      ".X\n",
      "20\t5\t20\n",
      "20\t5\t20\n",
      "20\t5\t20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(indexer.getStrFromDoc(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get obj from Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accelerating Convergence of Iterative Processes \n",
      "  Wegstein, J. H. \n",
      "  CA580602 JB March 22, 1978  9:09 PM \n",
      "  \n",
      "  A technique is discussed which, when applied to an iterative procedure for the solution of an equation, accelerates the rate of convergence if the iteration converges and induces convergence if the iteration diverges.  An illustrative example is given.\n"
     ]
    }
   ],
   "source": [
    "obj = indexer.getObjFromDoc(20)\n",
    "print(obj.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get element frequencies from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'acceler': 1, 'process': 1, 'solut': 1, 'ca': 1, 'procedur': 1, 'an': 3, 'rate': 1, 'if': 2, 'given': 1, 'techniqu': 1, 'for': 1, 'diverg': 1, 'when': 1, 'to': 1, 'which': 1, 'appli': 1, 'is': 2, 'pm': 1, 'march': 1, 'induc': 1, 'wegstein': 1, 'discuss': 1, 'jb': 1, 'of': 3, 'iter': 4, 'converg': 4, 'exampl': 1, 'equat': 1, 'illustr': 1, 'accelerat': 1, 'the': 4, -1: 47}\n"
     ]
    }
   ],
   "source": [
    "print(indexer.getEfFromDoc(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get document frequencies from element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3715': 1, '4003': 2, '3520': 2, '3712': 2, '3496': 2, '3571': 1, '3494': 1, '3495': 1, '3492': 1, '3491': 1, '3320': 1, '3322': 1, '3326': 1, '3656': 1, '3437': 1, '3652': 1, '3808': 1, '3554': 1, '20': 1, '3551': 1, '3250': 2, '3794': 1, '3797': 1, '3254': 2, '3255': 1, '4143': 1, '4199': 1, '3805': 1, '3853': 1, '3999': 1, '3750': 1, '3996': 2, '4138': 1, '3723': 1, '3993': 1, '3928': 1, '3489': 1, '3761': 2, '3762': 1, '3837': 2, '3764': 1, '3938': 1, '3767': 1, '3480': 1, '3936': 1, '3838': 1, '3930': 1, '3486': 1, '3401': 1, '3332': 1, '3817': 1, '3407': 1, '4070': 1, '4039': 1, '4186': 1, '3642': 1, '4178': 2, '3562': 1, '4026': 1, '3248': 1, '3566': 1, '3883': 1, '3564': 1, '3243': 1, '3241': 1, '3569': 1, '4024': 1, '3245': 1, '3814': 1, '3444': 3, '4180': 2, '3568': 1, '3948': 1, '3772': 1, '3680': 1, '3777': 1, '3410': 1, '3821': 1, '3820': 1, '3687': 1, '3942': 1, '3649': 1, '3709': 1, '3947': 1, '4109': 1, '3273': 1, '3308': 1, '4108': 1, '3672': 1, '3661': 1, '4200': 1, '3677': 1, '3278': 1, '3301': 1, '3386': 1, '3387': 1, '3823': 1, '4128': 1, '3471': 1, '3380': 2, '3381': 1, '4123': 1, '4122': 2, '3576': 1, '3478': 1, '3573': 2, '4124': 1, '4196': 2, '4033': 1, '4063': 1, '4095': 2, '4016': 1, '3822': 1, '3958': 1, '3584': 1, '3585': 2, '3586': 1, '3662': 1, '3746': 1, '3747': 1, '3744': 1, '4140': 1, '4053': 1, '4139': 1, '3263': 1, '3518': 1, '4112': 2, '3264': 1, '3269': 1, '3310': 1, '4203': 1, '3467': 1, '3509': 1, '3464': 1, '3395': 3, '3462': 2, '4051': 1, '3399': 1, '3502': 1, '3503': 1, '3505': 2, '3469': 1, '4058': 3, '3681': 1, '644': 1, '3691': 1, '4147': 1, '4113': 2, '4189': 1, '4103': 1, '3591': 1, '3613': 2, '3614': 1, '3596': 2, '4151': 1, '3826': 2, '3751': 1, '3619': 1, '3599': 1, '3598': 1, '4175': 2, '3802': 2, '3749': 1, '3944': 1, '4104': 1, '3294': 1, '3295': 1, '3296': 1, '3290': 1, '3776': 1, '3453': 1, '3450': 1, '3451': 1, '3457': 1, '3934': 1, '4065': 1, '3513': 1, '3512': 1, '4068': 1, '3459': 2, '3360': 1, '3696': 1, '3863': 1, '3898': 1, '3893': 1, '3884': 1, '3391': 1, '3694': 1, '3870': 1, '3871': 1, '3608': 1, '3875': 2, '4181': 1, '3527': 1, '3525': 2, '3728': 3, '3289': 3, '227': 1, '3286': 1, '93': 1, '4042': 2, '3528': 1, '3280': 1, '11': 1, '3206': 1, '4176': 1, '3994': 1, '3449': 1, '14': 1, '3379': 1, '3378': 1, '3376': 2, '3447': 1, '3446': 1, '3373': 1, '3372': 1, '1180': 1, '3684': 1, '3966': 1, '3967': 1, '3960': 1, '3968': 1, '4080': 2, '4082': 1, '3868': 2, '3901': 2, '3879': 1, '3636': 1, '3548': 1, '3634': 1, '3908': 1, '3633': 1, '3865': 1, '3549': 1, '3534': 1, '3673': 1, '3737': 1, '3538': 1, '3222': 1, '3731': 1, '3783': 1, '3236': 1, '3342': 2, '3340': 1, '3833': 1, '4005': 2, '3345': 1, '4120': 3, '3769': 2, '4173': 1, '3978': 1, '3629': 4, '4092': 1, '3911': 2, '3623': 1, '3625': 3, '3624': 1, '3919': 1, '3663': 1, '3354': 1, '3356': 1, '3350': 1, '3700': 1, '3707': 1, '3704': 2, '4152': 1, '3545': 1, '3781': 1, '3786': 1, '3228': 1, '3543': 1, '3423': 1, '3227': 1, '3789': 1, '3221': 1, '3220': 1, '3424': 1, '4014': 1, '3882': 2, '3988': 1, '3989': 1, '4046': 1, '3985': 1, '4002': 3, -1: 343}\n"
     ]
    }
   ],
   "source": [
    "print(indexer.getDfFromEl('wegstein'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Queries Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queriesPath = 'data/cacm/cacm.qry'\n",
    "parser = ParserCACM()\n",
    "queriesIndexer = IndexerCACM(queriesPath, ParserCACM())\n",
    "\n",
    "# If Index isn't already builded\n",
    "#queriesIndexer.createRepIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RelevantParser(Parser):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        Parser.__init__(self, '')\n",
    "        self.curId = None\n",
    "    \n",
    "    def nextDocument(self):\n",
    "        \n",
    "        if self.curId==None:\n",
    "            self.curLine = self.file.readline()\n",
    "            if self.curLine!=None:\n",
    "                self.curId = ((self.curLine).split())[0]\n",
    "            \n",
    "        id = self.curId\n",
    "        text = ''\n",
    "        \n",
    "        while(id==self.curId and self.curLine!=''):\n",
    "            text += self.curLine\n",
    "            pos2 = self.file.tell()\n",
    "            self.curLine = self.file.readline()\n",
    "            if self.curLine!='':\n",
    "                self.curId = ((self.curLine).split())[0]\n",
    "        \n",
    "        if text=='':\n",
    "            return None\n",
    "        \n",
    "        return self.getDocument(text)\n",
    "        \n",
    "    def getDocument(self, text):\n",
    "        \n",
    "        tab = \\\n",
    "        [\n",
    "            [(i.split())[1], int((i.split())[2]), int((i.split())[3])] \\\n",
    "            for i in text.split('\\n')[:-1] \\\n",
    "        ]\n",
    "        identifier = str(int(text.split()[0]))\n",
    "        \n",
    "        return Document(identifier, others={'tab': tab})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevantPath = 'data/cacm/cacm.rel'\n",
    "relevantIndexer = Indexer(relevantPath, RelevantParser())\n",
    "\n",
    "# If Index and Inv Index aren't already builded\n",
    "#relevantIndexer.createIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "\n",
    "    def __init__(self, id, text=\"\", el=None, relevants=None):\n",
    "        \n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.el = el\n",
    "        self.relevants = relevants\n",
    "        \n",
    "def query(id, queriesIndexer, relevantIndexer):\n",
    "    \n",
    "    id = str(id)\n",
    "    text = queriesIndexer.getObjFromDoc(id).getText()\n",
    "    el = queriesIndexer.getEfFromDoc(id)\n",
    "    relevants = relevantIndexer.getObjFromDoc(id).get('tab')\n",
    "    \n",
    "    return Query(id, text, el, relevants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Id : ', '1')\n",
      "('Text : ', ' \\n  \\n   1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)    \\n  \\n   What articles exist which deal with TSS (Time Sharing System), an operating system for IBM computers?')\n",
      "('Elements : ', {'comput': 1, 'deal': 1, 'share': 1, 'an': 1, 'exist': 1, 'langmuir': 1, 'what': 1, 'richard': 1, 'system': 2, 'articl': 1, 'which': 1, 'tss': 2, 'comp': 1, 'lab': 1, 'with': 1, 'ibm': 1, 'serv': 1, 'alexand': 1, 'for': 1, 'operat': 1, 'time': 1, -1: 23})\n",
      "('Relevants : ', [['1410', 0, 0], ['1572', 0, 0], ['1605', 0, 0], ['2020', 0, 0], ['2358', 0, 0], ['2434', 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "q = query(1, queriesIndexer, relevantIndexer)\n",
    "print('Id : ', q.id)\n",
    "print('Text : ', q.text)\n",
    "print('Elements : ', q.el)\n",
    "print('Relevants : ', q.relevants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
